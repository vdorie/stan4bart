#ifndef MODELS_HPP
#define MODELS_HPP
#define STAN__SERVICES__COMMAND_HPP
// #include <rstan/rstaninc.hpp>
// Code generated by Stan version 2.21.0


#if defined(__GNUC__) && (\
  (!defined(__clang__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6))) || \
  ( defined(__clang__) && (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 7))))
#  define SUPPRESS_DIAGNOSTIC 1
#endif

#define EIGEN_PERMANENTLY_DISABLE_STUPID_WARNINGS 1
#ifdef SUPPRESS_DIAGNOSTIC
#  pragma GCC diagnostic push
#  pragma GCC diagnostic ignored "-Wunknown-pragmas"
#  pragma GCC diagnostic ignored "-Wunused-variable"
#  pragma GCC diagnostic ignored "-Wunused-parameter"
#  pragma GCC diagnostic ignored "-Wunused-local-typedef"
#  pragma GCC diagnostic ignored "-Wunneeded-internal-declaration"
#  pragma GCC diagnostic ignored "-Wunused-function"
#  pragma GCC diagnostic ignored "-Wsign-compare"
#  pragma GCC diagnostic ignored "-Wlanguage-extension-token"
#  pragma GCC diagnostic ignored "-Winfinite-recursion"
#  pragma GCC diagnostic ignored "-Wignored-qualifiers"
#endif

#include <stan/model/model_header.hpp>

// TODO: it would be nice to include less
#include <stan/math/version.hpp>
#if STAN_MATH_MAJOR > 3 || (STAN_MATH_MAJOR == 3 && STAN_MATH_MINOR >= 2)
#  include <stan/math/prim.hpp>
#else
#  include <stan/math/prim/mat.hpp>
#endif

#ifdef SUPPRESS_DIAGNOSTIC
#  pragma GCC diagnostic pop
#endif


// define some operations for Eigen maps
namespace stan { namespace math {

template <typename T>
inline T get_base1(const Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, 1> >& x,
                          size_t m, const char* error_msg, size_t idx) {
  check_range("[]", "x", x.size(), m, idx, error_msg);
  return x(m - 1);
}

template <typename T>
inline Eigen::Matrix<T, Eigen::Dynamic, 1> segment(
    const Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, 1> >& v, size_t i, size_t n) {
  check_greater("segment", "n", i, 0.0);
  check_less_or_equal("segment", "n", i, static_cast<size_t>(v.rows()));
  if (n != 0) {
    check_greater("segment", "n", i + n - 1, 0.0);
    check_less_or_equal("segment", "n", i + n - 1,
                        static_cast<size_t>(v.rows()));
  }

  return v.segment(i - 1, n);
}

template <typename T, typename = require_eigen_t<T>>
inline int rows(const Eigen::Map<const T>& m) {
  return m.rows();
}

} }

namespace model_continuous_namespace {

using std::istream;
using std::string;
using std::stringstream;
using std::vector;
using stan::io::dump;
using stan::math::lgamma;
using stan::model::prob_grad;
using namespace stan::math;

static int current_statement_begin__;

stan::io::program_reader prog_reader__() {
    stan::io::program_reader reader;
    reader.add_event(0, 0, "start", "model_continuous");
    reader.add_event(424, 422, "end", "model_continuous");
    return reader;
}

/* template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type, Eigen::Dynamic, 1>
make_theta_L(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& tau,
                 const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& scale,
                 const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& zeta,
                 const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& rho,
                 const Eigen::Matrix<T7__, Eigen::Dynamic, 1>& z_T, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type local_scalar_t__; */
template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
Eigen::Matrix<typename boost::math::tools::promote_args<
  T2__,
  typename T3__::Scalar,
  typename T4__::Scalar,
  typename T5__::Scalar,
  typename boost::math::tools::promote_args<
    typename T6__::Scalar,
    typename T7__::Scalar>::type>::type, Eigen::Dynamic, 1>
make_theta_L(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const T3__& tau,
                 const T4__& scale,
                 const T5__& zeta,
                 const T6__& rho,
                 const T7__& z_T,
                 std::ostream* pstream__)
{
    typedef typename boost::math::tools::promote_args<
      T2__,
      typename T3__::Scalar,
      typename T4__::Scalar,
      typename T5__::Scalar,
      typename boost::math::tools::promote_args<
        typename T6__::Scalar,
        typename T7__::Scalar>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 6;
        validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> theta_L(len_theta_L);
        stan::math::initialize(theta_L, DUMMY_VAR__);
        stan::math::fill(theta_L, DUMMY_VAR__);

        current_statement_begin__ = 7;
        int zeta_mark(0);
        (void) zeta_mark;  // dummy to suppress unused var warning
        stan::math::fill(zeta_mark, std::numeric_limits<int>::min());
        stan::math::assign(zeta_mark,1);

        current_statement_begin__ = 8;
        int rho_mark(0);
        (void) rho_mark;  // dummy to suppress unused var warning
        stan::math::fill(rho_mark, std::numeric_limits<int>::min());
        stan::math::assign(rho_mark,1);

        current_statement_begin__ = 9;
        int z_T_mark(0);
        (void) z_T_mark;  // dummy to suppress unused var warning
        stan::math::fill(z_T_mark, std::numeric_limits<int>::min());
        stan::math::assign(z_T_mark,1);

        current_statement_begin__ = 10;
        int theta_L_mark(0);
        (void) theta_L_mark;  // dummy to suppress unused var warning
        stan::math::fill(theta_L_mark, std::numeric_limits<int>::min());
        stan::math::assign(theta_L_mark,1);


        current_statement_begin__ = 13;
        for (int i = 1; i <= size(p); ++i) {
            {
            current_statement_begin__ = 14;
            int nc(0);
            (void) nc;  // dummy to suppress unused var warning
            stan::math::fill(nc, std::numeric_limits<int>::min());
            stan::math::assign(nc,get_base1(p, i, "p", 1));


            current_statement_begin__ = 15;
            if (as_bool(logical_eq(nc, 1))) {

                current_statement_begin__ = 16;
                stan::model::assign(theta_L, 
                            stan::model::cons_list(stan::model::index_uni(theta_L_mark), stan::model::nil_index_list()), 
                            ((get_base1(tau, i, "tau", 1) * get_base1(scale, i, "scale", 1)) * dispersion), 
                            "assigning variable theta_L");
                current_statement_begin__ = 18;
                stan::math::assign(theta_L_mark, (theta_L_mark + 1));
            } else {
                {
                current_statement_begin__ = 21;
                validate_non_negative_index("T_i", "nc", nc);
                validate_non_negative_index("T_i", "nc", nc);
                Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> T_i(nc, nc);
                stan::math::initialize(T_i, DUMMY_VAR__);
                stan::math::fill(T_i, DUMMY_VAR__);

                current_statement_begin__ = 22;
                local_scalar_t__ std_dev(DUMMY_VAR__);
                (void) std_dev;  // dummy to suppress unused var warning
                stan::math::initialize(std_dev, DUMMY_VAR__);
                stan::math::fill(std_dev, DUMMY_VAR__);

                current_statement_begin__ = 23;
                local_scalar_t__ T21(DUMMY_VAR__);
                (void) T21;  // dummy to suppress unused var warning
                stan::math::initialize(T21, DUMMY_VAR__);
                stan::math::fill(T21, DUMMY_VAR__);

                current_statement_begin__ = 24;
                local_scalar_t__ trace_T_i(DUMMY_VAR__);
                (void) trace_T_i;  // dummy to suppress unused var warning
                stan::math::initialize(trace_T_i, DUMMY_VAR__);
                stan::math::fill(trace_T_i, DUMMY_VAR__);
                stan::math::assign(trace_T_i,(square(((get_base1(tau, i, "tau", 1) * get_base1(scale, i, "scale", 1)) * dispersion)) * nc));

                current_statement_begin__ = 25;
                validate_non_negative_index("pi", "nc", nc);
                Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> pi(nc);
                stan::math::initialize(pi, DUMMY_VAR__);
                stan::math::fill(pi, DUMMY_VAR__);
                stan::math::assign(pi,segment(zeta, zeta_mark, nc));


                current_statement_begin__ = 26;
                stan::math::assign(pi, divide(pi, sum(pi)));
                current_statement_begin__ = 29;
                stan::math::assign(zeta_mark, (zeta_mark + nc));
                current_statement_begin__ = 30;
                stan::math::assign(std_dev, stan::math::sqrt((get_base1(pi, 1, "pi", 1) * trace_T_i)));
                current_statement_begin__ = 31;
                stan::model::assign(T_i, 
                            stan::model::cons_list(stan::model::index_uni(1), stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list())), 
                            std_dev, 
                            "assigning variable T_i");
                current_statement_begin__ = 34;
                stan::math::assign(std_dev, stan::math::sqrt((get_base1(pi, 2, "pi", 1) * trace_T_i)));
                current_statement_begin__ = 35;
                stan::math::assign(T21, ((2.0 * get_base1(rho, rho_mark, "rho", 1)) - 1.0));
                current_statement_begin__ = 36;
                stan::math::assign(rho_mark, (rho_mark + 1));
                current_statement_begin__ = 37;
                stan::model::assign(T_i, 
                            stan::model::cons_list(stan::model::index_uni(2), stan::model::cons_list(stan::model::index_uni(2), stan::model::nil_index_list())), 
                            (std_dev * stan::math::sqrt((1.0 - square(T21)))), 
                            "assigning variable T_i");
                current_statement_begin__ = 38;
                stan::model::assign(T_i, 
                            stan::model::cons_list(stan::model::index_uni(2), stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list())), 
                            (std_dev * T21), 
                            "assigning variable T_i");
                current_statement_begin__ = 40;
                for (int r = 2; r <= (nc - 1); ++r) {
                    {
                    current_statement_begin__ = 41;
                    int rp1(0);
                    (void) rp1;  // dummy to suppress unused var warning
                    stan::math::fill(rp1, std::numeric_limits<int>::min());
                    stan::math::assign(rp1,(r + 1));

                    current_statement_begin__ = 42;
                    validate_non_negative_index("T_row", "r", r);
                    Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> T_row(r);
                    stan::math::initialize(T_row, DUMMY_VAR__);
                    stan::math::fill(T_row, DUMMY_VAR__);
                    stan::math::assign(T_row,segment(z_T, z_T_mark, r));

                    current_statement_begin__ = 43;
                    local_scalar_t__ scale_factor(DUMMY_VAR__);
                    (void) scale_factor;  // dummy to suppress unused var warning
                    stan::math::initialize(scale_factor, DUMMY_VAR__);
                    stan::math::fill(scale_factor, DUMMY_VAR__);
                    stan::math::assign(scale_factor,(stan::math::sqrt((get_base1(rho, rho_mark, "rho", 1) / dot_self(T_row))) * std_dev));


                    current_statement_begin__ = 44;
                    stan::math::assign(z_T_mark, (z_T_mark + r));
                    current_statement_begin__ = 45;
                    stan::math::assign(std_dev, stan::math::sqrt((get_base1(pi, rp1, "pi", 1) * trace_T_i)));
                    current_statement_begin__ = 46;
                    for (int c = 1; c <= r; ++c) {
                        current_statement_begin__ = 46;
                        stan::model::assign(T_i, 
                                    stan::model::cons_list(stan::model::index_uni(rp1), stan::model::cons_list(stan::model::index_uni(c), stan::model::nil_index_list())), 
                                    (get_base1(T_row, c, "T_row", 1) * scale_factor), 
                                    "assigning variable T_i");
                    }
                    current_statement_begin__ = 47;
                    stan::model::assign(T_i, 
                                stan::model::cons_list(stan::model::index_uni(rp1), stan::model::cons_list(stan::model::index_uni(rp1), stan::model::nil_index_list())), 
                                (stan::math::sqrt((1.0 - get_base1(rho, rho_mark, "rho", 1))) * std_dev), 
                                "assigning variable T_i");
                    current_statement_begin__ = 48;
                    stan::math::assign(rho_mark, (rho_mark + 1));
                    }
                }
                current_statement_begin__ = 52;
                for (int c = 1; c <= nc; ++c) {
                    current_statement_begin__ = 52;
                    for (int r = c; r <= nc; ++r) {

                        current_statement_begin__ = 53;
                        stan::model::assign(theta_L, 
                                    stan::model::cons_list(stan::model::index_uni(theta_L_mark), stan::model::nil_index_list()), 
                                    get_base1(T_i, r, c, "T_i", 1), 
                                    "assigning variable theta_L");
                        current_statement_begin__ = 54;
                        stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                    }
                }
                }
            }
            }
        }
        current_statement_begin__ = 58;
        return stan::math::promote_scalar<fun_return_scalar_t__>(theta_L);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_theta_L_functor__ {
    template <typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T3__, T4__, T5__, typename boost::math::tools::promote_args<T6__, T7__>::type>::type, Eigen::Dynamic, 1>
    operator()(const int& len_theta_L,
                 const std::vector<int>& p,
                 const T2__& dispersion,
                 const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& tau,
                 const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& scale,
                 const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& zeta,
                 const Eigen::Matrix<T6__, Eigen::Dynamic, 1>& rho,
                 const Eigen::Matrix<T7__, Eigen::Dynamic, 1>& z_T, std::ostream* pstream__) const {
        return make_theta_L(len_theta_L, p, dispersion, tau, scale, zeta, rho, z_T, pstream__);
    }
};

/* template <typename T0__, typename T1__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1>
make_b(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_b,
           const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& theta_L,
           const std::vector<int>& p,
           const std::vector<int>& l, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__; */
template <typename T0__, typename T1__>
Eigen::Matrix<
  typename boost::math::tools::promote_args<typename T0__::Scalar, typename T1__::Scalar>::type,
  Eigen::Dynamic, 1
>
make_b(const T0__& z_b,
       const T1__& theta_L,
       const std::vector<int>& p,
       const std::vector<int>& l, std::ostream* pstream__)
{
    typedef typename boost::math::tools::promote_args<typename T0__::Scalar, typename T1__::Scalar>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 63;
        validate_non_negative_index("b", "rows(z_b)", rows(z_b));
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> b(rows(z_b));
        stan::math::initialize(b, DUMMY_VAR__);
        stan::math::fill(b, DUMMY_VAR__);

        current_statement_begin__ = 64;
        int b_mark(0);
        (void) b_mark;  // dummy to suppress unused var warning
        stan::math::fill(b_mark, std::numeric_limits<int>::min());
        stan::math::assign(b_mark,1);

        current_statement_begin__ = 65;
        int theta_L_mark(0);
        (void) theta_L_mark;  // dummy to suppress unused var warning
        stan::math::fill(theta_L_mark, std::numeric_limits<int>::min());
        stan::math::assign(theta_L_mark,1);


        current_statement_begin__ = 66;
        for (int i = 1; i <= size(p); ++i) {
            {
            current_statement_begin__ = 67;
            int nc(0);
            (void) nc;  // dummy to suppress unused var warning
            stan::math::fill(nc, std::numeric_limits<int>::min());
            stan::math::assign(nc,get_base1(p, i, "p", 1));


            current_statement_begin__ = 68;
            if (as_bool(logical_eq(nc, 1))) {
                {
                current_statement_begin__ = 69;
                local_scalar_t__ theta_L_start(DUMMY_VAR__);
                (void) theta_L_start;  // dummy to suppress unused var warning
                stan::math::initialize(theta_L_start, DUMMY_VAR__);
                stan::math::fill(theta_L_start, DUMMY_VAR__);
                stan::math::assign(theta_L_start,get_base1(theta_L, theta_L_mark, "theta_L", 1));


                current_statement_begin__ = 70;
                for (int s = b_mark; s <= ((b_mark + get_base1(l, i, "l", 1)) - 1); ++s) {
                    current_statement_begin__ = 71;
                    stan::model::assign(b, 
                                stan::model::cons_list(stan::model::index_uni(s), stan::model::nil_index_list()), 
                                (theta_L_start * get_base1(z_b, s, "z_b", 1)), 
                                "assigning variable b");
                }
                current_statement_begin__ = 72;
                stan::math::assign(b_mark, (b_mark + get_base1(l, i, "l", 1)));
                current_statement_begin__ = 73;
                stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                }
            } else {
                {
                current_statement_begin__ = 76;
                validate_non_negative_index("T_i", "nc", nc);
                validate_non_negative_index("T_i", "nc", nc);
                Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, Eigen::Dynamic> T_i(nc, nc);
                stan::math::initialize(T_i, DUMMY_VAR__);
                stan::math::fill(T_i, DUMMY_VAR__);
                stan::math::assign(T_i,rep_matrix(0, nc, nc));


                current_statement_begin__ = 77;
                for (int c = 1; c <= nc; ++c) {

                    current_statement_begin__ = 78;
                    stan::model::assign(T_i, 
                                stan::model::cons_list(stan::model::index_uni(c), stan::model::cons_list(stan::model::index_uni(c), stan::model::nil_index_list())), 
                                get_base1(theta_L, theta_L_mark, "theta_L", 1), 
                                "assigning variable T_i");
                    current_statement_begin__ = 79;
                    stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                    current_statement_begin__ = 80;
                    for (int r = (c + 1); r <= nc; ++r) {

                        current_statement_begin__ = 81;
                        stan::model::assign(T_i, 
                                    stan::model::cons_list(stan::model::index_uni(r), stan::model::cons_list(stan::model::index_uni(c), stan::model::nil_index_list())), 
                                    get_base1(theta_L, theta_L_mark, "theta_L", 1), 
                                    "assigning variable T_i");
                        current_statement_begin__ = 82;
                        stan::math::assign(theta_L_mark, (theta_L_mark + 1));
                    }
                }
                current_statement_begin__ = 85;
                for (int j = 1; j <= get_base1(l, i, "l", 1); ++j) {
                    {
                    current_statement_begin__ = 86;
                    validate_non_negative_index("temp", "nc", nc);
                    Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> temp(nc);
                    stan::math::initialize(temp, DUMMY_VAR__);
                    stan::math::fill(temp, DUMMY_VAR__);
                    stan::math::assign(temp,multiply(T_i, segment(z_b, b_mark, nc)));


                    current_statement_begin__ = 87;
                    stan::math::assign(b_mark, (b_mark - 1));
                    current_statement_begin__ = 88;
                    for (int s = 1; s <= nc; ++s) {
                        current_statement_begin__ = 88;
                        stan::model::assign(b, 
                                    stan::model::cons_list(stan::model::index_uni((b_mark + s)), stan::model::nil_index_list()), 
                                    get_base1(temp, s, "temp", 1), 
                                    "assigning variable b");
                    }
                    current_statement_begin__ = 89;
                    stan::math::assign(b_mark, (b_mark + (nc + 1)));
                    }
                }
                }
            }
            }
        }
        current_statement_begin__ = 93;
        return stan::math::promote_scalar<fun_return_scalar_t__>(b);
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct make_b_functor__ {
    template <typename T0__, typename T1__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_b,
           const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& theta_L,
           const std::vector<int>& p,
           const std::vector<int>& l, std::ostream* pstream__) const {
        return make_b(z_b, theta_L, p, l, pstream__);
    }
};

template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__, typename T_lp__, typename T_lp_accum__>
typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__, T7__, T_lp__>::type>::type
decov_lp(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_b,
             const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& z_T,
             const Eigen::Matrix<T2__, Eigen::Dynamic, 1>& rho,
             const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& zeta,
             const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& tau,
             const std::vector<T5__>& regularization,
             const std::vector<T6__>& delta,
             const Eigen::Matrix<T7__, Eigen::Dynamic, 1>& shape,
             const int& t,
             const std::vector<int>& p, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__, T7__, T_lp__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 100;
        int pos_reg(0);
        (void) pos_reg;  // dummy to suppress unused var warning
        stan::math::fill(pos_reg, std::numeric_limits<int>::min());
        stan::math::assign(pos_reg,1);

        current_statement_begin__ = 101;
        int pos_rho(0);
        (void) pos_rho;  // dummy to suppress unused var warning
        stan::math::fill(pos_rho, std::numeric_limits<int>::min());
        stan::math::assign(pos_rho,1);


        current_statement_begin__ = 102;
        lp_accum__.add(normal_log(z_b, 0, 1));
        current_statement_begin__ = 103;
        lp_accum__.add(normal_log(z_T, 0, 1));
        current_statement_begin__ = 104;
        for (int i = 1; i <= t; ++i) {
            current_statement_begin__ = 104;
            if (as_bool(logical_gt(get_base1(p, i, "p", 1), 1))) {
                {
                current_statement_begin__ = 105;
                validate_non_negative_index("shape1", "(get_base1(p, i, \"p\", 1) - 1)", (get_base1(p, i, "p", 1) - 1));
                Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> shape1((get_base1(p, i, "p", 1) - 1));
                stan::math::initialize(shape1, DUMMY_VAR__);
                stan::math::fill(shape1, DUMMY_VAR__);

                current_statement_begin__ = 106;
                validate_non_negative_index("shape2", "(get_base1(p, i, \"p\", 1) - 1)", (get_base1(p, i, "p", 1) - 1));
                Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> shape2((get_base1(p, i, "p", 1) - 1));
                stan::math::initialize(shape2, DUMMY_VAR__);
                stan::math::fill(shape2, DUMMY_VAR__);

                current_statement_begin__ = 107;
                local_scalar_t__ nu(DUMMY_VAR__);
                (void) nu;  // dummy to suppress unused var warning
                stan::math::initialize(nu, DUMMY_VAR__);
                stan::math::fill(nu, DUMMY_VAR__);
                stan::math::assign(nu,(get_base1(regularization, pos_reg, "regularization", 1) + (0.5 * (get_base1(p, i, "p", 1) - 2))));


                current_statement_begin__ = 108;
                stan::math::assign(pos_reg, (pos_reg + 1));
                current_statement_begin__ = 109;
                stan::model::assign(shape1, 
                            stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                            nu, 
                            "assigning variable shape1");
                current_statement_begin__ = 110;
                stan::model::assign(shape2, 
                            stan::model::cons_list(stan::model::index_uni(1), stan::model::nil_index_list()), 
                            nu, 
                            "assigning variable shape2");
                current_statement_begin__ = 111;
                for (int j = 2; j <= (get_base1(p, i, "p", 1) - 1); ++j) {

                    current_statement_begin__ = 112;
                    stan::math::assign(nu, (nu - 0.5));
                    current_statement_begin__ = 113;
                    stan::model::assign(shape1, 
                                stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list()), 
                                (0.5 * j), 
                                "assigning variable shape1");
                    current_statement_begin__ = 114;
                    stan::model::assign(shape2, 
                                stan::model::cons_list(stan::model::index_uni(j), stan::model::nil_index_list()), 
                                nu, 
                                "assigning variable shape2");
                }
                current_statement_begin__ = 116;
                lp_accum__.add(beta_log(stan::model::rvalue(rho, stan::model::cons_list(stan::model::index_min_max(pos_rho, ((pos_rho + get_base1(p, i, "p", 1)) - 2)), stan::model::nil_index_list()), "rho"), shape1, shape2));
                current_statement_begin__ = 117;
                stan::math::assign(pos_rho, (pos_rho + (get_base1(p, i, "p", 1) - 1)));
                }
            }
        }
        current_statement_begin__ = 119;
        lp_accum__.add(gamma_log(zeta, delta, 1));
        current_statement_begin__ = 120;
        lp_accum__.add(gamma_log(tau, shape, 1));
        current_statement_begin__ = 121;
        return stan::math::promote_scalar<fun_return_scalar_t__>(get_lp(lp__, lp_accum__));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct decov_lp_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__, typename T6__, typename T7__, typename T_lp__, typename T_lp_accum__>
        typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__, T6__, T7__, T_lp__>::type>::type
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_b,
             const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& z_T,
             const Eigen::Matrix<T2__, Eigen::Dynamic, 1>& rho,
             const Eigen::Matrix<T3__, Eigen::Dynamic, 1>& zeta,
             const Eigen::Matrix<T4__, Eigen::Dynamic, 1>& tau,
             const std::vector<T5__>& regularization,
             const std::vector<T6__>& delta,
             const Eigen::Matrix<T7__, Eigen::Dynamic, 1>& shape,
             const int& t,
             const std::vector<int>& p, T_lp__& lp__, T_lp_accum__& lp_accum__, std::ostream* pstream__) const {
        return decov_lp(z_b, z_T, rho, zeta, tau, regularization, delta, shape, t, p, lp__, lp_accum__, pstream__);
    }
};

/* template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type, Eigen::Dynamic, 1>
hs_prior(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic, 1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale,
             const T5__& c2, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type local_scalar_t__; */
template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__>
Eigen::Matrix<typename boost::math::tools::promote_args<typename T0__::Scalar, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type, Eigen::Dynamic, 1>
hs_prior(const T0__& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic, 1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale,
             const T5__& c2, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<typename T0__::Scalar, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type local_scalar_t__;

    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 126;
        int K(0);
        (void) K;  // dummy to suppress unused var warning
        stan::math::fill(K, std::numeric_limits<int>::min());
        stan::math::assign(K,rows(z_beta));

        current_statement_begin__ = 127;
        validate_non_negative_index("lambda", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> lambda(K);
        stan::math::initialize(lambda, DUMMY_VAR__);
        stan::math::fill(lambda, DUMMY_VAR__);
        stan::math::assign(lambda,elt_multiply(get_base1(local, 1, "local", 1), stan::math::sqrt(get_base1(local, 2, "local", 1))));

        current_statement_begin__ = 128;
        local_scalar_t__ tau(DUMMY_VAR__);
        (void) tau;  // dummy to suppress unused var warning
        stan::math::initialize(tau, DUMMY_VAR__);
        stan::math::fill(tau, DUMMY_VAR__);
        stan::math::assign(tau,(((get_base1(global, 1, "global", 1) * stan::math::sqrt(get_base1(global, 2, "global", 1))) * global_prior_scale) * error_scale));

        current_statement_begin__ = 129;
        validate_non_negative_index("lambda2", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> lambda2(K);
        stan::math::initialize(lambda2, DUMMY_VAR__);
        stan::math::fill(lambda2, DUMMY_VAR__);
        stan::math::assign(lambda2,square(lambda));

        current_statement_begin__ = 130;
        validate_non_negative_index("lambda_tilde", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> lambda_tilde(K);
        stan::math::initialize(lambda_tilde, DUMMY_VAR__);
        stan::math::fill(lambda_tilde, DUMMY_VAR__);
        stan::math::assign(lambda_tilde,stan::math::sqrt(elt_divide(multiply(c2, lambda2), add(c2, multiply(square(tau), lambda2)))));


        current_statement_begin__ = 131;
        return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(elt_multiply(z_beta, lambda_tilde), tau));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct hs_prior_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_beta,
             const std::vector<T1__>& global,
             const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic, 1> >& local,
             const T3__& global_prior_scale,
             const T4__& error_scale,
             const T5__& c2, std::ostream* pstream__) const {
        return hs_prior(z_beta, global, local, global_prior_scale, error_scale, c2, pstream__);
    }
};

/* template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type, Eigen::Dynamic, 1>
hsplus_prior(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic, 1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale,
                 const T5__& c2, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type local_scalar_t__; */
template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__>
Eigen::Matrix<typename boost::math::tools::promote_args<typename T0__::Scalar, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type, Eigen::Dynamic, 1>
hsplus_prior(T0__ z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic, 1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale,
                 const T5__& c2, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<typename T0__::Scalar, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 136;
        int K(0);
        (void) K;  // dummy to suppress unused var warning
        stan::math::fill(K, std::numeric_limits<int>::min());
        stan::math::assign(K,rows(z_beta));

        current_statement_begin__ = 137;
        validate_non_negative_index("lambda", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> lambda(K);
        stan::math::initialize(lambda, DUMMY_VAR__);
        stan::math::fill(lambda, DUMMY_VAR__);
        stan::math::assign(lambda,elt_multiply(get_base1(local, 1, "local", 1), stan::math::sqrt(get_base1(local, 2, "local", 1))));

        current_statement_begin__ = 138;
        validate_non_negative_index("eta", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> eta(K);
        stan::math::initialize(eta, DUMMY_VAR__);
        stan::math::fill(eta, DUMMY_VAR__);
        stan::math::assign(eta,elt_multiply(get_base1(local, 3, "local", 1), stan::math::sqrt(get_base1(local, 4, "local", 1))));

        current_statement_begin__ = 139;
        local_scalar_t__ tau(DUMMY_VAR__);
        (void) tau;  // dummy to suppress unused var warning
        stan::math::initialize(tau, DUMMY_VAR__);
        stan::math::fill(tau, DUMMY_VAR__);
        stan::math::assign(tau,(((get_base1(global, 1, "global", 1) * stan::math::sqrt(get_base1(global, 2, "global", 1))) * global_prior_scale) * error_scale));

        current_statement_begin__ = 140;
        validate_non_negative_index("lambda_eta2", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> lambda_eta2(K);
        stan::math::initialize(lambda_eta2, DUMMY_VAR__);
        stan::math::fill(lambda_eta2, DUMMY_VAR__);
        stan::math::assign(lambda_eta2,square(elt_multiply(lambda, eta)));

        current_statement_begin__ = 141;
        validate_non_negative_index("lambda_tilde", "K", K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> lambda_tilde(K);
        stan::math::initialize(lambda_tilde, DUMMY_VAR__);
        stan::math::fill(lambda_tilde, DUMMY_VAR__);
        stan::math::assign(lambda_tilde,stan::math::sqrt(elt_divide(multiply(c2, lambda_eta2), add(c2, multiply(square(tau), lambda_eta2)))));


        current_statement_begin__ = 143;
        return stan::math::promote_scalar<fun_return_scalar_t__>(multiply(elt_multiply(z_beta, lambda_tilde), tau));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct hsplus_prior_functor__ {
    template <typename T0__, typename T1__, typename T2__, typename T3__, typename T4__, typename T5__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__, T3__, typename boost::math::tools::promote_args<T4__, T5__>::type>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& z_beta,
                 const std::vector<T1__>& global,
                 const std::vector<Eigen::Matrix<T2__, Eigen::Dynamic, 1> >& local,
                 const T3__& global_prior_scale,
                 const T4__& error_scale,
                 const T5__& c2, std::ostream* pstream__) const {
        return hsplus_prior(z_beta, global, local, global_prior_scale, error_scale, c2, pstream__);
    }
};

template <typename T0__, typename T1__>
typename boost::math::tools::promote_args<T0__, T1__>::type
CFt(const T0__& z,
        const T1__& df, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {
        {
        current_statement_begin__ = 147;
        local_scalar_t__ z2(DUMMY_VAR__);
        (void) z2;  // dummy to suppress unused var warning
        stan::math::initialize(z2, DUMMY_VAR__);
        stan::math::fill(z2, DUMMY_VAR__);
        stan::math::assign(z2,square(z));

        current_statement_begin__ = 148;
        local_scalar_t__ z3(DUMMY_VAR__);
        (void) z3;  // dummy to suppress unused var warning
        stan::math::initialize(z3, DUMMY_VAR__);
        stan::math::fill(z3, DUMMY_VAR__);
        stan::math::assign(z3,(z2 * z));

        current_statement_begin__ = 149;
        local_scalar_t__ z5(DUMMY_VAR__);
        (void) z5;  // dummy to suppress unused var warning
        stan::math::initialize(z5, DUMMY_VAR__);
        stan::math::fill(z5, DUMMY_VAR__);
        stan::math::assign(z5,(z2 * z3));

        current_statement_begin__ = 150;
        local_scalar_t__ z7(DUMMY_VAR__);
        (void) z7;  // dummy to suppress unused var warning
        stan::math::initialize(z7, DUMMY_VAR__);
        stan::math::fill(z7, DUMMY_VAR__);
        stan::math::assign(z7,(z2 * z5));

        current_statement_begin__ = 151;
        local_scalar_t__ z9(DUMMY_VAR__);
        (void) z9;  // dummy to suppress unused var warning
        stan::math::initialize(z9, DUMMY_VAR__);
        stan::math::fill(z9, DUMMY_VAR__);
        stan::math::assign(z9,(z2 * z7));

        current_statement_begin__ = 152;
        local_scalar_t__ df2(DUMMY_VAR__);
        (void) df2;  // dummy to suppress unused var warning
        stan::math::initialize(df2, DUMMY_VAR__);
        stan::math::fill(df2, DUMMY_VAR__);
        stan::math::assign(df2,square(df));

        current_statement_begin__ = 153;
        local_scalar_t__ df3(DUMMY_VAR__);
        (void) df3;  // dummy to suppress unused var warning
        stan::math::initialize(df3, DUMMY_VAR__);
        stan::math::fill(df3, DUMMY_VAR__);
        stan::math::assign(df3,(df2 * df));

        current_statement_begin__ = 154;
        local_scalar_t__ df4(DUMMY_VAR__);
        (void) df4;  // dummy to suppress unused var warning
        stan::math::initialize(df4, DUMMY_VAR__);
        stan::math::fill(df4, DUMMY_VAR__);
        stan::math::assign(df4,(df2 * df2));


        current_statement_begin__ = 155;
        return stan::math::promote_scalar<fun_return_scalar_t__>(((((z + ((z3 + z) / (4 * df))) + ((((5 * z5) + (16 * z3)) + (3 * z)) / (96 * df2))) + (((((3 * z7) + (19 * z5)) + (17 * z3)) - (15 * z)) / (384 * df3))) + ((((((79 * z9) + (776 * z7)) + (1482 * z5)) - (1920 * z3)) - (945 * z)) / (92160 * df4))));
        }
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct CFt_functor__ {
    template <typename T0__, typename T1__>
        typename boost::math::tools::promote_args<T0__, T1__>::type
    operator()(const T0__& z,
        const T1__& df, std::ostream* pstream__) const {
        return CFt(z, df, pstream__);
    }
};

/* template <typename T2__, typename T5__>
Eigen::Matrix<typename boost::math::tools::promote_args<T2__, T5__>::type, Eigen::Dynamic, 1>
csr_matrix_times_vector2(const int& m,
                         const int& n,
                         const Eigen::Matrix<T2__, Eigen::Dynamic, 1>& w,
                         const std::vector<int>& v,
                         const std::vector<int>& u,
                         const Eigen::Matrix<T5__, Eigen::Dynamic, 1>& b, std::ostream* pstream__); */
template <typename T2__, typename T5__>
Eigen::Matrix<typename boost::math::tools::promote_args<typename T2__::Scalar, typename T5__::Scalar>::type, Eigen::Dynamic, 1>
csr_matrix_times_vector3(const int& m,
                         const int& n,
                         const T2__& w,
                         const std::vector<int>& v,
                         const std::vector<int>& u,
                         const T5__& b,
                         std::ostream* pstream__)
{
  Eigen::Map<const Eigen::SparseMatrix<typename T2__::Scalar, Eigen::RowMajor> >
    sm(m, n, w.size(), &u[0], &v[0], &w[0]);
  return sm * b;
}


template <typename T0__, typename T1__, typename T2__>
Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic, 1>
pw_gauss(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& y,
             const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& eta,
             const T2__& sigma, std::ostream* pstream__) {
    typedef typename boost::math::tools::promote_args<T0__, T1__, T2__>::type local_scalar_t__;
    typedef local_scalar_t__ fun_return_scalar_t__;
    const static bool propto__ = true;
    (void) propto__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

    int current_statement_begin__ = -1;
    try {

        current_statement_begin__ = 164;
        return stan::math::promote_scalar<fun_return_scalar_t__>(subtract((-(0.5) * stan::math::log((6.283185307179586232 * sigma))), divide(multiply(0.5, square(subtract(y, eta))), sigma)));
    } catch (const std::exception& e) {
        stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
        // Next line prevents compiler griping about no return
        throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
    }
}


struct pw_gauss_functor__ {
    template <typename T0__, typename T1__, typename T2__>
        Eigen::Matrix<typename boost::math::tools::promote_args<T0__, T1__, T2__>::type, Eigen::Dynamic, 1>
    operator()(const Eigen::Matrix<T0__, Eigen::Dynamic, 1>& y,
             const Eigen::Matrix<T1__, Eigen::Dynamic, 1>& eta,
             const T2__& sigma, std::ostream* pstream__) const {
        return pw_gauss(y, eta, sigma, pstream__);
    }
};

#include <meta_header.hpp>
 class model_continuous
  : public stan::model::model_base_crtp<model_continuous> {
private:
        int N;
        int K;
        matrix_d X;
        int len_y;
        double lb_y;
        double ub_y;
        vector_d y;
        int has_intercept;
        int prior_dist;
        int prior_dist_for_intercept;
        int prior_dist_for_aux;
        int has_weights;
        vector_d weights;
        vector_d offset_;
        vector_d prior_scale;
        double prior_scale_for_intercept;
        double prior_scale_for_aux;
        vector_d prior_mean;
        double prior_mean_for_intercept;
        double prior_mean_for_aux;
        vector_d prior_df;
        double prior_df_for_intercept;
        double prior_df_for_aux;
        double global_prior_df;
        double global_prior_scale;
        double slab_df;
        double slab_scale;
        std::vector<int> num_normals;
        int t;
        std::vector<int> p;
        std::vector<int> l;
        int q;
        int len_theta_L;
        vector_d shape;
        vector_d scale;
        int len_concentration;
        std::vector<double> concentration;
        int len_regularization;
        std::vector<double> regularization;
        int num_non_zero;
        vector_d w;
        std::vector<int> v;
        std::vector<int> u;
        int link;
        int family;
        int is_continuous;
        int len_z_T;
        int len_var_group;
        int len_rho;
        int pos;
        std::vector<double> delta;
        int hs;
public:
    model_continuous(
        int N,
        int K,
        matrix_d X,
        int len_y,
        double lb_y,
        double ub_y,
        vector_d y,
        int has_intercept,
        int prior_dist,
        int prior_dist_for_intercept,
        int prior_dist_for_aux,
        int has_weights,
        vector_d weights,
        vector_d offset_,
        vector_d prior_scale,
        double prior_scale_for_intercept,
        double prior_scale_for_aux,
        vector_d prior_mean,
        double prior_mean_for_intercept,
        double prior_mean_for_aux,
        vector_d prior_df,
        double prior_df_for_intercept,
        double prior_df_for_aux,
        double global_prior_df,
        double global_prior_scale,
        double slab_df,
        double slab_scale,
        std::vector<int> num_normals,
        int t,
        std::vector<int> p,
        std::vector<int> l,
        int q,
        int len_theta_L,
        vector_d shape,
        vector_d scale,
        int len_concentration,
        std::vector<double> concentration,
        int len_regularization,
        std::vector<double> regularization,
        int num_non_zero,
        vector_d w,
        std::vector<int> v,
        std::vector<int> u,
        int link,
        int family,
        int is_continuous,
        int len_z_T,
        int len_var_group,
        int len_rho,
        int pos,
        std::vector<double> delta,
        int hs) :
      model_base_crtp(0),
      N(N),
      K(K),
      X(X),
      len_y(len_y), 
      ub_y(ub_y),
      y(y),
      has_intercept(has_intercept),
      prior_dist(prior_dist),
      prior_dist_for_intercept(prior_dist_for_intercept),
      prior_dist_for_aux(prior_dist_for_aux),
      has_weights(has_weights),
      weights(weights),
      offset_(offset_),
      prior_scale(prior_scale),
      prior_scale_for_intercept(prior_scale_for_intercept),
      prior_scale_for_aux(prior_scale_for_aux),
      prior_mean(prior_mean),
      prior_mean_for_intercept(prior_mean_for_intercept),
      prior_mean_for_aux(prior_mean_for_aux),
      prior_df(prior_df),
      prior_df_for_intercept(prior_df_for_intercept),
      prior_df_for_aux(prior_df_for_aux),
      global_prior_df(global_prior_df),
      global_prior_scale(global_prior_scale),
      slab_df(slab_df),
      slab_scale(slab_scale),
      num_normals(num_normals),
      t(t),
      p(p),
      l(l),
      q(q),
      len_theta_L(len_theta_L),
      shape(shape),
      scale(scale),
      len_concentration(len_concentration),
      concentration(concentration),
      len_regularization(len_regularization),
      regularization(regularization),
      num_non_zero(num_non_zero),
      w(w),
      v(v),
      u(u),
      link(link),
      family(family),
      is_continuous(is_continuous),
      len_z_T(len_z_T),
      len_var_group(len_var_group),
      len_rho(len_rho),
      pos(pos),
      delta(delta),
      hs(hs)
    {
      num_params_r__ = 
        has_intercept + // gammma
        (prior_dist == 7 ? sum(num_normals) : K) + // z_beta
        hs + // global
        hs * K + // local
        (hs > 0 ? 1 : 0) + // caux
        (prior_dist == 5 || prior_dist == 6 ? K : 0) + // mix
        (prior_dist == 6 ? 1 : 0) + // one_over_lambda
        q + // z_b
        len_z_T + // z_T
        len_rho + // rho
        len_concentration + // zeta
        t + // tau
        1; // + // aux_unscaled; transformed not part of num_params_r
        // 1 + // aux
        // K + // beta
        // q + // b
        // len_theta_L; // theta_L
    }
    
    model_continuous(stan::io::var_context& context__,
        std::ostream* pstream__ = 0)
        : model_base_crtp(0) {
        ctor_body(context__, 0, pstream__);
    }

    model_continuous(stan::io::var_context& context__,
        unsigned int random_seed__,
        std::ostream* pstream__ = 0)
        : model_base_crtp(0) {
        ctor_body(context__, random_seed__, pstream__);
    }

    void ctor_body(stan::io::var_context& context__,
                   unsigned int random_seed__,
                   std::ostream* pstream__) {
        typedef double local_scalar_t__;

        boost::ecuyer1988 base_rng__ =
          stan::services::util::create_rng(random_seed__, 0);
        (void) base_rng__;  // suppress unused var warning

        current_statement_begin__ = -1;

        static const char* function__ = "model_continuous_namespace::model_continuous";
        (void) function__;  // dummy to suppress unused var warning
        size_t pos__;
        (void) pos__;  // dummy to suppress unused var warning
        std::vector<int> vals_i__;
        std::vector<double> vals_r__;
        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        try {
            // initialize data block variables from context__
            current_statement_begin__ = 169;
            context__.validate_dims("data initialization", "N", "int", context__.to_vec());
            N = int(0);
            vals_i__ = context__.vals_i("N");
            pos__ = 0;
            N = vals_i__[pos__++];
            check_greater_or_equal(function__, "N", N, 0);

            current_statement_begin__ = 170;
            context__.validate_dims("data initialization", "K", "int", context__.to_vec());
            K = int(0);
            vals_i__ = context__.vals_i("K");
            pos__ = 0;
            K = vals_i__[pos__++];
            check_greater_or_equal(function__, "K", K, 0);

            current_statement_begin__ = 173;
            validate_non_negative_index("X", "N", N);
            validate_non_negative_index("X", "K", K);
            context__.validate_dims("data initialization", "X", "matrix_d", context__.to_vec(N,K));
            X = Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>(N, K);
            vals_r__ = context__.vals_r("X");
            pos__ = 0;
            size_t X_j_2_max__ = K;
            size_t X_j_1_max__ = N;
            for (size_t j_2__ = 0; j_2__ < X_j_2_max__; ++j_2__) {
                for (size_t j_1__ = 0; j_1__ < X_j_1_max__; ++j_1__) {
                    X(j_1__, j_2__) = vals_r__[pos__++];
                }
            }

            current_statement_begin__ = 175;
            context__.validate_dims("data initialization", "len_y", "int", context__.to_vec());
            len_y = int(0);
            vals_i__ = context__.vals_i("len_y");
            pos__ = 0;
            len_y = vals_i__[pos__++];
            check_greater_or_equal(function__, "len_y", len_y, 0);

            current_statement_begin__ = 176;
            context__.validate_dims("data initialization", "lb_y", "double", context__.to_vec());
            lb_y = double(0);
            vals_r__ = context__.vals_r("lb_y");
            pos__ = 0;
            lb_y = vals_r__[pos__++];

            current_statement_begin__ = 177;
            context__.validate_dims("data initialization", "ub_y", "double", context__.to_vec());
            ub_y = double(0);
            vals_r__ = context__.vals_r("ub_y");
            pos__ = 0;
            ub_y = vals_r__[pos__++];
            check_greater_or_equal(function__, "ub_y", ub_y, lb_y);

            current_statement_begin__ = 178;
            validate_non_negative_index("y", "len_y", len_y);
            context__.validate_dims("data initialization", "y", "vector_d", context__.to_vec(len_y));
            y = Eigen::Matrix<double, Eigen::Dynamic, 1>(len_y);
            vals_r__ = context__.vals_r("y");
            pos__ = 0;
            size_t y_j_1_max__ = len_y;
            for (size_t j_1__ = 0; j_1__ < y_j_1_max__; ++j_1__) {
                y(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "y", y, lb_y);
            check_less_or_equal(function__, "y", y, ub_y);

            current_statement_begin__ = 181;
            context__.validate_dims("data initialization", "has_intercept", "int", context__.to_vec());
            has_intercept = int(0);
            vals_i__ = context__.vals_i("has_intercept");
            pos__ = 0;
            has_intercept = vals_i__[pos__++];
            check_greater_or_equal(function__, "has_intercept", has_intercept, 0);
            check_less_or_equal(function__, "has_intercept", has_intercept, 1);

            current_statement_begin__ = 185;
            context__.validate_dims("data initialization", "prior_dist", "int", context__.to_vec());
            prior_dist = int(0);
            vals_i__ = context__.vals_i("prior_dist");
            pos__ = 0;
            prior_dist = vals_i__[pos__++];
            check_greater_or_equal(function__, "prior_dist", prior_dist, 0);
            check_less_or_equal(function__, "prior_dist", prior_dist, 7);

            current_statement_begin__ = 186;
            context__.validate_dims("data initialization", "prior_dist_for_intercept", "int", context__.to_vec());
            prior_dist_for_intercept = int(0);
            vals_i__ = context__.vals_i("prior_dist_for_intercept");
            pos__ = 0;
            prior_dist_for_intercept = vals_i__[pos__++];
            check_greater_or_equal(function__, "prior_dist_for_intercept", prior_dist_for_intercept, 0);
            check_less_or_equal(function__, "prior_dist_for_intercept", prior_dist_for_intercept, 2);

            current_statement_begin__ = 189;
            context__.validate_dims("data initialization", "prior_dist_for_aux", "int", context__.to_vec());
            prior_dist_for_aux = int(0);
            vals_i__ = context__.vals_i("prior_dist_for_aux");
            pos__ = 0;
            prior_dist_for_aux = vals_i__[pos__++];
            check_greater_or_equal(function__, "prior_dist_for_aux", prior_dist_for_aux, 0);
            check_less_or_equal(function__, "prior_dist_for_aux", prior_dist_for_aux, 3);

            current_statement_begin__ = 192;
            context__.validate_dims("data initialization", "has_weights", "int", context__.to_vec());
            has_weights = int(0);
            vals_i__ = context__.vals_i("has_weights");
            pos__ = 0;
            has_weights = vals_i__[pos__++];
            check_greater_or_equal(function__, "has_weights", has_weights, 0);
            check_less_or_equal(function__, "has_weights", has_weights, 1);

            current_statement_begin__ = 193;
            validate_non_negative_index("weights", "(has_weights ? N : 0 )", (has_weights ? N : 0 ));
            context__.validate_dims("data initialization", "weights", "vector_d", context__.to_vec((has_weights ? N : 0 )));
            weights = Eigen::Matrix<double, Eigen::Dynamic, 1>((has_weights ? N : 0 ));
            vals_r__ = context__.vals_r("weights");
            pos__ = 0;
            size_t weights_j_1_max__ = (has_weights ? N : 0 );
            for (size_t j_1__ = 0; j_1__ < weights_j_1_max__; ++j_1__) {
                weights(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 195;
            validate_non_negative_index("offset_", "N", N);
            context__.validate_dims("data initialization", "offset_", "vector_d", context__.to_vec(N));
            offset_ = Eigen::Matrix<double, Eigen::Dynamic, 1>(N);
            vals_r__ = context__.vals_r("offset_");
            pos__ = 0;
            size_t offset__j_1_max__ = N;
            for (size_t j_1__ = 0; j_1__ < offset__j_1_max__; ++j_1__) {
                offset_(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 198;
            validate_non_negative_index("prior_scale", "K", K);
            context__.validate_dims("data initialization", "prior_scale", "vector_d", context__.to_vec(K));
            prior_scale = Eigen::Matrix<double, Eigen::Dynamic, 1>(K);
            vals_r__ = context__.vals_r("prior_scale");
            pos__ = 0;
            size_t prior_scale_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < prior_scale_j_1_max__; ++j_1__) {
                prior_scale(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "prior_scale", prior_scale, 0);

            current_statement_begin__ = 199;
            context__.validate_dims("data initialization", "prior_scale_for_intercept", "double", context__.to_vec());
            prior_scale_for_intercept = double(0);
            vals_r__ = context__.vals_r("prior_scale_for_intercept");
            pos__ = 0;
            prior_scale_for_intercept = vals_r__[pos__++];
            check_greater_or_equal(function__, "prior_scale_for_intercept", prior_scale_for_intercept, 0);

            current_statement_begin__ = 200;
            context__.validate_dims("data initialization", "prior_scale_for_aux", "double", context__.to_vec());
            prior_scale_for_aux = double(0);
            vals_r__ = context__.vals_r("prior_scale_for_aux");
            pos__ = 0;
            prior_scale_for_aux = vals_r__[pos__++];
            check_greater_or_equal(function__, "prior_scale_for_aux", prior_scale_for_aux, 0);

            current_statement_begin__ = 202;
            validate_non_negative_index("prior_mean", "K", K);
            context__.validate_dims("data initialization", "prior_mean", "vector_d", context__.to_vec(K));
            prior_mean = Eigen::Matrix<double, Eigen::Dynamic, 1>(K);
            vals_r__ = context__.vals_r("prior_mean");
            pos__ = 0;
            size_t prior_mean_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < prior_mean_j_1_max__; ++j_1__) {
                prior_mean(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 203;
            context__.validate_dims("data initialization", "prior_mean_for_intercept", "double", context__.to_vec());
            prior_mean_for_intercept = double(0);
            vals_r__ = context__.vals_r("prior_mean_for_intercept");
            pos__ = 0;
            prior_mean_for_intercept = vals_r__[pos__++];

            current_statement_begin__ = 204;
            context__.validate_dims("data initialization", "prior_mean_for_aux", "double", context__.to_vec());
            prior_mean_for_aux = double(0);
            vals_r__ = context__.vals_r("prior_mean_for_aux");
            pos__ = 0;
            prior_mean_for_aux = vals_r__[pos__++];
            check_greater_or_equal(function__, "prior_mean_for_aux", prior_mean_for_aux, 0);

            current_statement_begin__ = 206;
            validate_non_negative_index("prior_df", "K", K);
            context__.validate_dims("data initialization", "prior_df", "vector_d", context__.to_vec(K));
            prior_df = Eigen::Matrix<double, Eigen::Dynamic, 1>(K);
            vals_r__ = context__.vals_r("prior_df");
            pos__ = 0;
            size_t prior_df_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < prior_df_j_1_max__; ++j_1__) {
                prior_df(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "prior_df", prior_df, 0);

            current_statement_begin__ = 207;
            context__.validate_dims("data initialization", "prior_df_for_intercept", "double", context__.to_vec());
            prior_df_for_intercept = double(0);
            vals_r__ = context__.vals_r("prior_df_for_intercept");
            pos__ = 0;
            prior_df_for_intercept = vals_r__[pos__++];
            check_greater_or_equal(function__, "prior_df_for_intercept", prior_df_for_intercept, 0);

            current_statement_begin__ = 208;
            context__.validate_dims("data initialization", "prior_df_for_aux", "double", context__.to_vec());
            prior_df_for_aux = double(0);
            vals_r__ = context__.vals_r("prior_df_for_aux");
            pos__ = 0;
            prior_df_for_aux = vals_r__[pos__++];
            check_greater_or_equal(function__, "prior_df_for_aux", prior_df_for_aux, 0);

            current_statement_begin__ = 210;
            context__.validate_dims("data initialization", "global_prior_df", "double", context__.to_vec());
            global_prior_df = double(0);
            vals_r__ = context__.vals_r("global_prior_df");
            pos__ = 0;
            global_prior_df = vals_r__[pos__++];
            check_greater_or_equal(function__, "global_prior_df", global_prior_df, 0);

            current_statement_begin__ = 211;
            context__.validate_dims("data initialization", "global_prior_scale", "double", context__.to_vec());
            global_prior_scale = double(0);
            vals_r__ = context__.vals_r("global_prior_scale");
            pos__ = 0;
            global_prior_scale = vals_r__[pos__++];
            check_greater_or_equal(function__, "global_prior_scale", global_prior_scale, 0);

            current_statement_begin__ = 212;
            context__.validate_dims("data initialization", "slab_df", "double", context__.to_vec());
            slab_df = double(0);
            vals_r__ = context__.vals_r("slab_df");
            pos__ = 0;
            slab_df = vals_r__[pos__++];
            check_greater_or_equal(function__, "slab_df", slab_df, 0);

            current_statement_begin__ = 213;
            context__.validate_dims("data initialization", "slab_scale", "double", context__.to_vec());
            slab_scale = double(0);
            vals_r__ = context__.vals_r("slab_scale");
            pos__ = 0;
            slab_scale = vals_r__[pos__++];
            check_greater_or_equal(function__, "slab_scale", slab_scale, 0);

            current_statement_begin__ = 214;
            validate_non_negative_index("num_normals", "(logical_eq(prior_dist, 7) ? K : 0 )", (logical_eq(prior_dist, 7) ? K : 0 ));
            context__.validate_dims("data initialization", "num_normals", "int", context__.to_vec((logical_eq(prior_dist, 7) ? K : 0 )));
            num_normals = std::vector<int>((logical_eq(prior_dist, 7) ? K : 0 ), int(0));
            vals_i__ = context__.vals_i("num_normals");
            pos__ = 0;
            size_t num_normals_k_0_max__ = (logical_eq(prior_dist, 7) ? K : 0 );
            for (size_t k_0__ = 0; k_0__ < num_normals_k_0_max__; ++k_0__) {
                num_normals[k_0__] = vals_i__[pos__++];
            }
            size_t num_normals_i_0_max__ = (logical_eq(prior_dist, 7) ? K : 0 );
            for (size_t i_0__ = 0; i_0__ < num_normals_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "num_normals[i_0__]", num_normals[i_0__], 2);
            }

            current_statement_begin__ = 218;
            context__.validate_dims("data initialization", "t", "int", context__.to_vec());
            t = int(0);
            vals_i__ = context__.vals_i("t");
            pos__ = 0;
            t = vals_i__[pos__++];
            check_greater_or_equal(function__, "t", t, 0);

            current_statement_begin__ = 219;
            validate_non_negative_index("p", "t", t);
            context__.validate_dims("data initialization", "p", "int", context__.to_vec(t));
            p = std::vector<int>(t, int(0));
            vals_i__ = context__.vals_i("p");
            pos__ = 0;
            size_t p_k_0_max__ = t;
            for (size_t k_0__ = 0; k_0__ < p_k_0_max__; ++k_0__) {
                p[k_0__] = vals_i__[pos__++];
            }
            size_t p_i_0_max__ = t;
            for (size_t i_0__ = 0; i_0__ < p_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "p[i_0__]", p[i_0__], 1);
            }

            current_statement_begin__ = 220;
            validate_non_negative_index("l", "t", t);
            context__.validate_dims("data initialization", "l", "int", context__.to_vec(t));
            l = std::vector<int>(t, int(0));
            vals_i__ = context__.vals_i("l");
            pos__ = 0;
            size_t l_k_0_max__ = t;
            for (size_t k_0__ = 0; k_0__ < l_k_0_max__; ++k_0__) {
                l[k_0__] = vals_i__[pos__++];
            }
            size_t l_i_0_max__ = t;
            for (size_t i_0__ = 0; i_0__ < l_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "l[i_0__]", l[i_0__], 1);
            }

            current_statement_begin__ = 221;
            context__.validate_dims("data initialization", "q", "int", context__.to_vec());
            q = int(0);
            vals_i__ = context__.vals_i("q");
            pos__ = 0;
            q = vals_i__[pos__++];
            check_greater_or_equal(function__, "q", q, 0);

            current_statement_begin__ = 222;
            context__.validate_dims("data initialization", "len_theta_L", "int", context__.to_vec());
            len_theta_L = int(0);
            vals_i__ = context__.vals_i("len_theta_L");
            pos__ = 0;
            len_theta_L = vals_i__[pos__++];
            check_greater_or_equal(function__, "len_theta_L", len_theta_L, 0);

            current_statement_begin__ = 225;
            validate_non_negative_index("shape", "t", t);
            context__.validate_dims("data initialization", "shape", "vector_d", context__.to_vec(t));
            shape = Eigen::Matrix<double, Eigen::Dynamic, 1>(t);
            vals_r__ = context__.vals_r("shape");
            pos__ = 0;
            size_t shape_j_1_max__ = t;
            for (size_t j_1__ = 0; j_1__ < shape_j_1_max__; ++j_1__) {
                shape(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "shape", shape, 0);

            current_statement_begin__ = 226;
            validate_non_negative_index("scale", "t", t);
            context__.validate_dims("data initialization", "scale", "vector_d", context__.to_vec(t));
            scale = Eigen::Matrix<double, Eigen::Dynamic, 1>(t);
            vals_r__ = context__.vals_r("scale");
            pos__ = 0;
            size_t scale_j_1_max__ = t;
            for (size_t j_1__ = 0; j_1__ < scale_j_1_max__; ++j_1__) {
                scale(j_1__) = vals_r__[pos__++];
            }
            check_greater_or_equal(function__, "scale", scale, 0);

            current_statement_begin__ = 227;
            context__.validate_dims("data initialization", "len_concentration", "int", context__.to_vec());
            len_concentration = int(0);
            vals_i__ = context__.vals_i("len_concentration");
            pos__ = 0;
            len_concentration = vals_i__[pos__++];
            check_greater_or_equal(function__, "len_concentration", len_concentration, 0);

            current_statement_begin__ = 228;
            validate_non_negative_index("concentration", "len_concentration", len_concentration);
            context__.validate_dims("data initialization", "concentration", "double", context__.to_vec(len_concentration));
            concentration = std::vector<double>(len_concentration, double(0));
            vals_r__ = context__.vals_r("concentration");
            pos__ = 0;
            size_t concentration_k_0_max__ = len_concentration;
            for (size_t k_0__ = 0; k_0__ < concentration_k_0_max__; ++k_0__) {
                concentration[k_0__] = vals_r__[pos__++];
            }
            size_t concentration_i_0_max__ = len_concentration;
            for (size_t i_0__ = 0; i_0__ < concentration_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "concentration[i_0__]", concentration[i_0__], 0);
            }

            current_statement_begin__ = 229;
            context__.validate_dims("data initialization", "len_regularization", "int", context__.to_vec());
            len_regularization = int(0);
            vals_i__ = context__.vals_i("len_regularization");
            pos__ = 0;
            len_regularization = vals_i__[pos__++];
            check_greater_or_equal(function__, "len_regularization", len_regularization, 0);

            current_statement_begin__ = 230;
            validate_non_negative_index("regularization", "len_regularization", len_regularization);
            context__.validate_dims("data initialization", "regularization", "double", context__.to_vec(len_regularization));
            regularization = std::vector<double>(len_regularization, double(0));
            vals_r__ = context__.vals_r("regularization");
            pos__ = 0;
            size_t regularization_k_0_max__ = len_regularization;
            for (size_t k_0__ = 0; k_0__ < regularization_k_0_max__; ++k_0__) {
                regularization[k_0__] = vals_r__[pos__++];
            }
            size_t regularization_i_0_max__ = len_regularization;
            for (size_t i_0__ = 0; i_0__ < regularization_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "regularization[i_0__]", regularization[i_0__], 0);
            }

            current_statement_begin__ = 233;
            context__.validate_dims("data initialization", "num_non_zero", "int", context__.to_vec());
            num_non_zero = int(0);
            vals_i__ = context__.vals_i("num_non_zero");
            pos__ = 0;
            num_non_zero = vals_i__[pos__++];
            check_greater_or_equal(function__, "num_non_zero", num_non_zero, 0);

            current_statement_begin__ = 234;
            validate_non_negative_index("w", "num_non_zero", num_non_zero);
            context__.validate_dims("data initialization", "w", "vector_d", context__.to_vec(num_non_zero));
            w = Eigen::Matrix<double, Eigen::Dynamic, 1>(num_non_zero);
            vals_r__ = context__.vals_r("w");
            pos__ = 0;
            size_t w_j_1_max__ = num_non_zero;
            for (size_t j_1__ = 0; j_1__ < w_j_1_max__; ++j_1__) {
                w(j_1__) = vals_r__[pos__++];
            }

            current_statement_begin__ = 235;
            validate_non_negative_index("v", "num_non_zero", num_non_zero);
            context__.validate_dims("data initialization", "v", "int", context__.to_vec(num_non_zero));
            v = std::vector<int>(num_non_zero, int(0));
            vals_i__ = context__.vals_i("v");
            pos__ = 0;
            size_t v_k_0_max__ = num_non_zero;
            for (size_t k_0__ = 0; k_0__ < v_k_0_max__; ++k_0__) {
                v[k_0__] = vals_i__[pos__++];
            }
            size_t v_i_0_max__ = num_non_zero;
            for (size_t i_0__ = 0; i_0__ < v_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "v[i_0__]", v[i_0__], 0);
                check_less_or_equal(function__, "v[i_0__]", v[i_0__], (q - 1));
            }

            current_statement_begin__ = 236;
            validate_non_negative_index("u", "(N + 1)", (N + 1));
            context__.validate_dims("data initialization", "u", "int", context__.to_vec((N + 1)));
            u = std::vector<int>((N + 1), int(0));
            vals_i__ = context__.vals_i("u");
            pos__ = 0;
            size_t u_k_0_max__ = (N + 1);
            for (size_t k_0__ = 0; k_0__ < u_k_0_max__; ++k_0__) {
                u[k_0__] = vals_i__[pos__++];
            }
            size_t u_i_0_max__ = (N + 1);
            for (size_t i_0__ = 0; i_0__ < u_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "u[i_0__]", u[i_0__], 0);
                check_less_or_equal(function__, "u[i_0__]", u[i_0__], (rows(w) + 1));
            }


            // initialize transformed data variables
            current_statement_begin__ = 239;
            link = int(0);
            stan::math::fill(link, std::numeric_limits<int>::min());
            stan::math::assign(link,1);

            current_statement_begin__ = 240;
            family = int(0);
            stan::math::fill(family, std::numeric_limits<int>::min());
            stan::math::assign(family,1);

            current_statement_begin__ = 241;
            is_continuous = int(0);
            stan::math::fill(is_continuous, std::numeric_limits<int>::min());
            stan::math::assign(is_continuous,1);

            current_statement_begin__ = 243;
            len_z_T = int(0);
            stan::math::fill(len_z_T, std::numeric_limits<int>::min());
            stan::math::assign(len_z_T,0);

            current_statement_begin__ = 244;
            len_var_group = int(0);
            stan::math::fill(len_var_group, std::numeric_limits<int>::min());
            stan::math::assign(len_var_group,sum(p));

            current_statement_begin__ = 245;
            len_rho = int(0);
            stan::math::fill(len_rho, std::numeric_limits<int>::min());
            stan::math::assign(len_rho,(sum(p) - t));

            current_statement_begin__ = 246;
            pos = int(0);
            stan::math::fill(pos, std::numeric_limits<int>::min());
            stan::math::assign(pos,1);

            current_statement_begin__ = 247;
            validate_non_negative_index("delta", "len_concentration", len_concentration);
            delta = std::vector<double>(len_concentration, double(0));
            stan::math::fill(delta, DUMMY_VAR__);

            current_statement_begin__ = 248;
            hs = int(0);
            stan::math::fill(hs, std::numeric_limits<int>::min());

            // execute transformed data statements
            current_statement_begin__ = 249;
            if (as_bool(logical_lte(prior_dist, 2))) {
                current_statement_begin__ = 249;
                stan::math::assign(hs, 0);
            } else if (as_bool(logical_eq(prior_dist, 3))) {
                current_statement_begin__ = 250;
                stan::math::assign(hs, 2);
            } else if (as_bool(logical_eq(prior_dist, 4))) {
                current_statement_begin__ = 251;
                stan::math::assign(hs, 4);
            } else {
                current_statement_begin__ = 252;
                stan::math::assign(hs, 0);
            }
            current_statement_begin__ = 254;
            for (int i = 1; i <= t; ++i) {

                current_statement_begin__ = 255;
                if (as_bool(logical_gt(get_base1(p, i, "p", 1), 1))) {

                    current_statement_begin__ = 256;
                    for (int j = 1; j <= get_base1(p, i, "p", 1); ++j) {

                        current_statement_begin__ = 257;
                        stan::model::assign(delta, 
                                    stan::model::cons_list(stan::model::index_uni(pos), stan::model::nil_index_list()), 
                                    get_base1(concentration, j, "concentration", 1), 
                                    "assigning variable delta");
                        current_statement_begin__ = 258;
                        stan::math::assign(pos, (pos + 1));
                    }
                }
                current_statement_begin__ = 261;
                for (int j = 3; j <= get_base1(p, i, "p", 1); ++j) {
                    current_statement_begin__ = 261;
                    stan::math::assign(len_z_T, (len_z_T + (get_base1(p, i, "p", 1) - 1)));
                }
            }

            // validate transformed data
            current_statement_begin__ = 239;
            check_greater_or_equal(function__, "link", link, 1);

            current_statement_begin__ = 240;
            check_greater_or_equal(function__, "family", family, 1);
            check_less_or_equal(function__, "family", family, 4);

            current_statement_begin__ = 241;
            check_greater_or_equal(function__, "is_continuous", is_continuous, 0);
            check_less_or_equal(function__, "is_continuous", is_continuous, 1);

            current_statement_begin__ = 243;
            check_greater_or_equal(function__, "len_z_T", len_z_T, 0);

            current_statement_begin__ = 244;
            check_greater_or_equal(function__, "len_var_group", len_var_group, 0);

            current_statement_begin__ = 245;
            check_greater_or_equal(function__, "len_rho", len_rho, 0);

            current_statement_begin__ = 246;
            check_greater_or_equal(function__, "pos", pos, 1);

            current_statement_begin__ = 247;
            size_t delta_i_0_max__ = len_concentration;
            for (size_t i_0__ = 0; i_0__ < delta_i_0_max__; ++i_0__) {
                check_greater_or_equal(function__, "delta[i_0__]", delta[i_0__], 0);
            }

            current_statement_begin__ = 248;
            check_greater_or_equal(function__, "hs", hs, 0);


            // validate, set parameter ranges
            num_params_r__ = 0U;
            param_ranges_i__.clear();
            current_statement_begin__ = 265;
            validate_non_negative_index("gamma", "has_intercept", has_intercept);
            num_params_r__ += (1 * has_intercept);
            current_statement_begin__ = 268;
            validate_non_negative_index("z_beta", "(logical_eq(prior_dist, 7) ? sum(num_normals) : K )", (logical_eq(prior_dist, 7) ? sum(num_normals) : K ));
            num_params_r__ += (logical_eq(prior_dist, 7) ? sum(num_normals) : K );
            current_statement_begin__ = 269;
            validate_non_negative_index("global", "hs", hs);
            num_params_r__ += (1 * hs);
            current_statement_begin__ = 270;
            validate_non_negative_index("local", "K", K);
            validate_non_negative_index("local", "hs", hs);
            num_params_r__ += (K * hs);
            current_statement_begin__ = 271;
            validate_non_negative_index("caux", "logical_gt(hs, 0)", logical_gt(hs, 0));
            num_params_r__ += (1 * logical_gt(hs, 0));
            current_statement_begin__ = 272;
            validate_non_negative_index("mix", "K", K);
            validate_non_negative_index("mix", "(primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)))", (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6))));
            num_params_r__ += (K * (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6))));
            current_statement_begin__ = 273;
            validate_non_negative_index("one_over_lambda", "logical_eq(prior_dist, 6)", logical_eq(prior_dist, 6));
            num_params_r__ += (1 * logical_eq(prior_dist, 6));
            current_statement_begin__ = 274;
            validate_non_negative_index("z_b", "q", q);
            num_params_r__ += q;
            current_statement_begin__ = 275;
            validate_non_negative_index("z_T", "len_z_T", len_z_T);
            num_params_r__ += len_z_T;
            current_statement_begin__ = 276;
            validate_non_negative_index("rho", "len_rho", len_rho);
            num_params_r__ += len_rho;
            current_statement_begin__ = 277;
            validate_non_negative_index("zeta", "len_concentration", len_concentration);
            num_params_r__ += len_concentration;
            current_statement_begin__ = 278;
            validate_non_negative_index("tau", "t", t);
            num_params_r__ += t;
            current_statement_begin__ = 280;
            num_params_r__ += 1;
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }
    }

    ~model_continuous() { }
    
    void set_offset(const double* offset) {
      offset_.resize(N);
      for (int i = 0; i < N; ++i)
        offset_(i) = offset[i];
    }


    void transform_inits(const stan::io::var_context& context__,
                         std::vector<int>& params_i__,
                         std::vector<double>& params_r__,
                         std::ostream* pstream__) const {
        typedef double local_scalar_t__;
        stan::io::writer<double> writer__(params_r__, params_i__);
        size_t pos__;
        (void) pos__; // dummy call to supress warning
        std::vector<double> vals_r__;
        std::vector<int> vals_i__;

        current_statement_begin__ = 265;
        if (!(context__.contains_r("gamma")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable gamma missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("gamma");
        pos__ = 0U;
        validate_non_negative_index("gamma", "has_intercept", has_intercept);
        context__.validate_dims("parameter initialization", "gamma", "double", context__.to_vec(has_intercept));
        std::vector<double> gamma(has_intercept, double(0));
        size_t gamma_k_0_max__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < gamma_k_0_max__; ++k_0__) {
            gamma[k_0__] = vals_r__[pos__++];
        }
        size_t gamma_i_0_max__ = has_intercept;
        for (size_t i_0__ = 0; i_0__ < gamma_i_0_max__; ++i_0__) {
            try {
                writer__.scalar_lub_unconstrain(stan::math::negative_infinity(), stan::math::positive_infinity(), gamma[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable gamma: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 268;
        if (!(context__.contains_r("z_beta")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable z_beta missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("z_beta");
        pos__ = 0U;
        validate_non_negative_index("z_beta", "(logical_eq(prior_dist, 7) ? sum(num_normals) : K )", (logical_eq(prior_dist, 7) ? sum(num_normals) : K ));
        context__.validate_dims("parameter initialization", "z_beta", "vector_d", context__.to_vec((logical_eq(prior_dist, 7) ? sum(num_normals) : K )));
        Eigen::Matrix<double, Eigen::Dynamic, 1> z_beta((logical_eq(prior_dist, 7) ? sum(num_normals) : K ));
        size_t z_beta_j_1_max__ = (logical_eq(prior_dist, 7) ? sum(num_normals) : K );
        for (size_t j_1__ = 0; j_1__ < z_beta_j_1_max__; ++j_1__) {
            z_beta(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_unconstrain(z_beta);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable z_beta: ") + e.what()), current_statement_begin__, prog_reader__());
        }

        current_statement_begin__ = 269;
        if (!(context__.contains_r("global")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable global missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("global");
        pos__ = 0U;
        validate_non_negative_index("global", "hs", hs);
        context__.validate_dims("parameter initialization", "global", "double", context__.to_vec(hs));
        std::vector<double> global(hs, double(0));
        size_t global_k_0_max__ = hs;
        for (size_t k_0__ = 0; k_0__ < global_k_0_max__; ++k_0__) {
            global[k_0__] = vals_r__[pos__++];
        }
        size_t global_i_0_max__ = hs;
        for (size_t i_0__ = 0; i_0__ < global_i_0_max__; ++i_0__) {
            try {
                writer__.scalar_lb_unconstrain(0, global[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable global: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 270;
        if (!(context__.contains_r("local")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable local missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("local");
        pos__ = 0U;
        validate_non_negative_index("local", "K", K);
        validate_non_negative_index("local", "hs", hs);
        context__.validate_dims("parameter initialization", "local", "vector_d", context__.to_vec(hs,K));
        std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > local(hs, Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
        size_t local_j_1_max__ = K;
        size_t local_k_0_max__ = hs;
        for (size_t j_1__ = 0; j_1__ < local_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < local_k_0_max__; ++k_0__) {
                local[k_0__](j_1__) = vals_r__[pos__++];
            }
        }
        size_t local_i_0_max__ = hs;
        for (size_t i_0__ = 0; i_0__ < local_i_0_max__; ++i_0__) {
            try {
                writer__.vector_lb_unconstrain(0, local[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable local: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 271;
        if (!(context__.contains_r("caux")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable caux missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("caux");
        pos__ = 0U;
        validate_non_negative_index("caux", "logical_gt(hs, 0)", logical_gt(hs, 0));
        context__.validate_dims("parameter initialization", "caux", "double", context__.to_vec(logical_gt(hs, 0)));
        std::vector<double> caux(logical_gt(hs, 0), double(0));
        size_t caux_k_0_max__ = logical_gt(hs, 0);
        for (size_t k_0__ = 0; k_0__ < caux_k_0_max__; ++k_0__) {
            caux[k_0__] = vals_r__[pos__++];
        }
        size_t caux_i_0_max__ = logical_gt(hs, 0);
        for (size_t i_0__ = 0; i_0__ < caux_i_0_max__; ++i_0__) {
            try {
                writer__.scalar_lb_unconstrain(0, caux[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable caux: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 272;
        if (!(context__.contains_r("mix")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable mix missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("mix");
        pos__ = 0U;
        validate_non_negative_index("mix", "K", K);
        validate_non_negative_index("mix", "(primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)))", (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6))));
        context__.validate_dims("parameter initialization", "mix", "vector_d", context__.to_vec((primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6))),K));
        std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > mix((primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6))), Eigen::Matrix<double, Eigen::Dynamic, 1>(K));
        size_t mix_j_1_max__ = K;
        size_t mix_k_0_max__ = (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)));
        for (size_t j_1__ = 0; j_1__ < mix_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mix_k_0_max__; ++k_0__) {
                mix[k_0__](j_1__) = vals_r__[pos__++];
            }
        }
        size_t mix_i_0_max__ = (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)));
        for (size_t i_0__ = 0; i_0__ < mix_i_0_max__; ++i_0__) {
            try {
                writer__.vector_lb_unconstrain(0, mix[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable mix: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 273;
        if (!(context__.contains_r("one_over_lambda")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable one_over_lambda missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("one_over_lambda");
        pos__ = 0U;
        validate_non_negative_index("one_over_lambda", "logical_eq(prior_dist, 6)", logical_eq(prior_dist, 6));
        context__.validate_dims("parameter initialization", "one_over_lambda", "double", context__.to_vec(logical_eq(prior_dist, 6)));
        std::vector<double> one_over_lambda(logical_eq(prior_dist, 6), double(0));
        size_t one_over_lambda_k_0_max__ = logical_eq(prior_dist, 6);
        for (size_t k_0__ = 0; k_0__ < one_over_lambda_k_0_max__; ++k_0__) {
            one_over_lambda[k_0__] = vals_r__[pos__++];
        }
        size_t one_over_lambda_i_0_max__ = logical_eq(prior_dist, 6);
        for (size_t i_0__ = 0; i_0__ < one_over_lambda_i_0_max__; ++i_0__) {
            try {
                writer__.scalar_lb_unconstrain(0, one_over_lambda[i_0__]);
            } catch (const std::exception& e) {
                stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable one_over_lambda: ") + e.what()), current_statement_begin__, prog_reader__());
            }
        }

        current_statement_begin__ = 274;
        if (!(context__.contains_r("z_b")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable z_b missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("z_b");
        pos__ = 0U;
        validate_non_negative_index("z_b", "q", q);
        context__.validate_dims("parameter initialization", "z_b", "vector_d", context__.to_vec(q));
        Eigen::Matrix<double, Eigen::Dynamic, 1> z_b(q);
        size_t z_b_j_1_max__ = q;
        for (size_t j_1__ = 0; j_1__ < z_b_j_1_max__; ++j_1__) {
            z_b(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_unconstrain(z_b);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable z_b: ") + e.what()), current_statement_begin__, prog_reader__());
        }

        current_statement_begin__ = 275;
        if (!(context__.contains_r("z_T")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable z_T missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("z_T");
        pos__ = 0U;
        validate_non_negative_index("z_T", "len_z_T", len_z_T);
        context__.validate_dims("parameter initialization", "z_T", "vector_d", context__.to_vec(len_z_T));
        Eigen::Matrix<double, Eigen::Dynamic, 1> z_T(len_z_T);
        size_t z_T_j_1_max__ = len_z_T;
        for (size_t j_1__ = 0; j_1__ < z_T_j_1_max__; ++j_1__) {
            z_T(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_unconstrain(z_T);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable z_T: ") + e.what()), current_statement_begin__, prog_reader__());
        }

        current_statement_begin__ = 276;
        if (!(context__.contains_r("rho")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable rho missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("rho");
        pos__ = 0U;
        validate_non_negative_index("rho", "len_rho", len_rho);
        context__.validate_dims("parameter initialization", "rho", "vector_d", context__.to_vec(len_rho));
        Eigen::Matrix<double, Eigen::Dynamic, 1> rho(len_rho);
        size_t rho_j_1_max__ = len_rho;
        for (size_t j_1__ = 0; j_1__ < rho_j_1_max__; ++j_1__) {
            rho(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_lub_unconstrain(0, 1, rho);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable rho: ") + e.what()), current_statement_begin__, prog_reader__());
        }

        current_statement_begin__ = 277;
        if (!(context__.contains_r("zeta")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable zeta missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("zeta");
        pos__ = 0U;
        validate_non_negative_index("zeta", "len_concentration", len_concentration);
        context__.validate_dims("parameter initialization", "zeta", "vector_d", context__.to_vec(len_concentration));
        Eigen::Matrix<double, Eigen::Dynamic, 1> zeta(len_concentration);
        size_t zeta_j_1_max__ = len_concentration;
        for (size_t j_1__ = 0; j_1__ < zeta_j_1_max__; ++j_1__) {
            zeta(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_lb_unconstrain(0, zeta);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable zeta: ") + e.what()), current_statement_begin__, prog_reader__());
        }

        current_statement_begin__ = 278;
        if (!(context__.contains_r("tau")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable tau missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("tau");
        pos__ = 0U;
        validate_non_negative_index("tau", "t", t);
        context__.validate_dims("parameter initialization", "tau", "vector_d", context__.to_vec(t));
        Eigen::Matrix<double, Eigen::Dynamic, 1> tau(t);
        size_t tau_j_1_max__ = t;
        for (size_t j_1__ = 0; j_1__ < tau_j_1_max__; ++j_1__) {
            tau(j_1__) = vals_r__[pos__++];
        }
        try {
            writer__.vector_lb_unconstrain(0, tau);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable tau: ") + e.what()), current_statement_begin__, prog_reader__());
        }

        current_statement_begin__ = 280;
        if (!(context__.contains_r("aux_unscaled")))
            stan::lang::rethrow_located(std::runtime_error(std::string("Variable aux_unscaled missing")), current_statement_begin__, prog_reader__());
        vals_r__ = context__.vals_r("aux_unscaled");
        pos__ = 0U;
        context__.validate_dims("parameter initialization", "aux_unscaled", "double", context__.to_vec());
        double aux_unscaled(0);
        aux_unscaled = vals_r__[pos__++];
        try {
            writer__.scalar_lb_unconstrain(0, aux_unscaled);
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(std::runtime_error(std::string("Error transforming variable aux_unscaled: ") + e.what()), current_statement_begin__, prog_reader__());
        }

        params_r__ = writer__.data_r();
        params_i__ = writer__.data_i();
    }

    void transform_inits(const stan::io::var_context& context,
                         Eigen::Matrix<double, Eigen::Dynamic, 1>& params_r,
                         std::ostream* pstream__) const {
      std::vector<double> params_r_vec;
      std::vector<int> params_i_vec;
      transform_inits(context, params_i_vec, params_r_vec, pstream__);
      params_r.resize(params_r_vec.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r(i) = params_r_vec[i];
    }


    template <bool propto__, bool jacobian__, typename T__>
    T__ log_prob(std::vector<T__>& params_r__,
                 std::vector<int>& params_i__,
                 std::ostream* pstream__ = 0) const {

        typedef T__ local_scalar_t__;

        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // dummy to suppress unused var warning

        T__ lp__(0.0);
        stan::math::accumulator<T__> lp_accum__;
        try {
            stan::io::reader<local_scalar_t__> in__(params_r__, params_i__);

            // model parameters
            current_statement_begin__ = 265;
            std::vector<local_scalar_t__> gamma;
            size_t gamma_d_0_max__ = has_intercept;
            gamma.reserve(gamma_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < gamma_d_0_max__; ++d_0__) {
                if (jacobian__)
                    gamma.push_back(in__.scalar_lub_constrain(stan::math::negative_infinity(), stan::math::positive_infinity(), lp__));
                else
                    gamma.push_back(in__.scalar_lub_constrain(stan::math::negative_infinity(), stan::math::positive_infinity()));
            }

            current_statement_begin__ = 268;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z_beta;
            (void) z_beta;  // dummy to suppress unused var warning
            if (jacobian__)
                z_beta = in__.vector_constrain((logical_eq(prior_dist, 7) ? sum(num_normals) : K ), lp__);
            else
                z_beta = in__.vector_constrain((logical_eq(prior_dist, 7) ? sum(num_normals) : K ));

            current_statement_begin__ = 269;
            std::vector<local_scalar_t__> global;
            size_t global_d_0_max__ = hs;
            global.reserve(global_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < global_d_0_max__; ++d_0__) {
                if (jacobian__)
                    global.push_back(in__.scalar_lb_constrain(0, lp__));
                else
                    global.push_back(in__.scalar_lb_constrain(0));
            }

            current_statement_begin__ = 270;
            std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > local;
            size_t local_d_0_max__ = hs;
            local.reserve(local_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < local_d_0_max__; ++d_0__) {
                if (jacobian__)
                    local.push_back(in__.vector_lb_constrain(0, K, lp__));
                else
                    local.push_back(in__.vector_lb_constrain(0, K));
            }

            current_statement_begin__ = 271;
            std::vector<local_scalar_t__> caux;
            size_t caux_d_0_max__ = logical_gt(hs, 0);
            caux.reserve(caux_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < caux_d_0_max__; ++d_0__) {
                if (jacobian__)
                    caux.push_back(in__.scalar_lb_constrain(0, lp__));
                else
                    caux.push_back(in__.scalar_lb_constrain(0));
            }

            current_statement_begin__ = 272;
            std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > mix;
            size_t mix_d_0_max__ = (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)));
            mix.reserve(mix_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < mix_d_0_max__; ++d_0__) {
                if (jacobian__)
                    mix.push_back(in__.vector_lb_constrain(0, K, lp__));
                else
                    mix.push_back(in__.vector_lb_constrain(0, K));
            }

            current_statement_begin__ = 273;
            std::vector<local_scalar_t__> one_over_lambda;
            size_t one_over_lambda_d_0_max__ = logical_eq(prior_dist, 6);
            one_over_lambda.reserve(one_over_lambda_d_0_max__);
            for (size_t d_0__ = 0; d_0__ < one_over_lambda_d_0_max__; ++d_0__) {
                if (jacobian__)
                    one_over_lambda.push_back(in__.scalar_lb_constrain(0, lp__));
                else
                    one_over_lambda.push_back(in__.scalar_lb_constrain(0));
            }

            current_statement_begin__ = 274;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z_b;
            (void) z_b;  // dummy to suppress unused var warning
            if (jacobian__)
                z_b = in__.vector_constrain(q, lp__);
            else
                z_b = in__.vector_constrain(q);

            current_statement_begin__ = 275;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z_T;
            (void) z_T;  // dummy to suppress unused var warning
            if (jacobian__)
                z_T = in__.vector_constrain(len_z_T, lp__);
            else
                z_T = in__.vector_constrain(len_z_T);

            current_statement_begin__ = 276;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> rho;
            (void) rho;  // dummy to suppress unused var warning
            if (jacobian__)
                rho = in__.vector_lub_constrain(0, 1, len_rho, lp__);
            else
                rho = in__.vector_lub_constrain(0, 1, len_rho);

            current_statement_begin__ = 277;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> zeta;
            (void) zeta;  // dummy to suppress unused var warning
            if (jacobian__)
                zeta = in__.vector_lb_constrain(0, len_concentration, lp__);
            else
                zeta = in__.vector_lb_constrain(0, len_concentration);

            current_statement_begin__ = 278;
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> tau;
            (void) tau;  // dummy to suppress unused var warning
            if (jacobian__)
                tau = in__.vector_lb_constrain(0, t, lp__);
            else
                tau = in__.vector_lb_constrain(0, t);

            current_statement_begin__ = 280;
            local_scalar_t__ aux_unscaled;
            (void) aux_unscaled;  // dummy to suppress unused var warning
            if (jacobian__)
                aux_unscaled = in__.scalar_lb_constrain(0, lp__);
            else
                aux_unscaled = in__.scalar_lb_constrain(0);

            // transformed parameters
            current_statement_begin__ = 283;
            local_scalar_t__ aux;
            (void) aux;  // dummy to suppress unused var warning
            stan::math::initialize(aux, DUMMY_VAR__);
            stan::math::fill(aux, DUMMY_VAR__);
            stan::math::assign(aux,(logical_eq(prior_dist_for_aux, 0) ? stan::math::promote_scalar<local_scalar_t__>(aux_unscaled) : stan::math::promote_scalar<local_scalar_t__>((logical_lte(prior_dist_for_aux, 2) ? stan::math::promote_scalar<local_scalar_t__>(((prior_scale_for_aux * aux_unscaled) + prior_mean_for_aux)) : stan::math::promote_scalar<local_scalar_t__>((prior_scale_for_aux * aux_unscaled)) )) ));

            current_statement_begin__ = 288;
            validate_non_negative_index("beta", "K", K);
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> beta(K);
            stan::math::initialize(beta, DUMMY_VAR__);
            stan::math::fill(beta, DUMMY_VAR__);

            current_statement_begin__ = 289;
            validate_non_negative_index("b", "q", q);
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> b(q);
            stan::math::initialize(b, DUMMY_VAR__);
            stan::math::fill(b, DUMMY_VAR__);

            current_statement_begin__ = 290;
            validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> theta_L(len_theta_L);
            stan::math::initialize(theta_L, DUMMY_VAR__);
            stan::math::fill(theta_L, DUMMY_VAR__);

            // transformed parameters block statements
            current_statement_begin__ = 291;
            if (as_bool(logical_eq(prior_dist, 0))) {
                current_statement_begin__ = 291;
                stan::math::assign(beta, z_beta);
            } else if (as_bool(logical_eq(prior_dist, 1))) {
                current_statement_begin__ = 292;
                stan::math::assign(beta, add(elt_multiply(z_beta, prior_scale), prior_mean));
            } else if (as_bool(logical_eq(prior_dist, 2))) {
                current_statement_begin__ = 293;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 294;
                    stan::model::assign(beta, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                ((CFt(get_base1(z_beta, k, "z_beta", 1), get_base1(prior_df, k, "prior_df", 1), pstream__) * get_base1(prior_scale, k, "prior_scale", 1)) + get_base1(prior_mean, k, "prior_mean", 1)), 
                                "assigning variable beta");
                }
            } else if (as_bool(logical_eq(prior_dist, 3))) {
                {
                current_statement_begin__ = 297;
                local_scalar_t__ c2(DUMMY_VAR__);
                (void) c2;  // dummy to suppress unused var warning
                stan::math::initialize(c2, DUMMY_VAR__);
                stan::math::fill(c2, DUMMY_VAR__);
                stan::math::assign(c2,(square(slab_scale) * get_base1(caux, 1, "caux", 1)));


                current_statement_begin__ = 298;
                if (as_bool((primitive_value(logical_eq(is_continuous, 1)) && primitive_value(logical_eq(family, 1))))) {
                    current_statement_begin__ = 299;
                    stan::math::assign(beta, hs_prior(z_beta, global, local, global_prior_scale, aux, c2, pstream__));
                } else {
                    current_statement_begin__ = 300;
                    stan::math::assign(beta, hs_prior(z_beta, global, local, global_prior_scale, 1, c2, pstream__));
                }
                }
            } else if (as_bool(logical_eq(prior_dist, 4))) {
                {
                current_statement_begin__ = 303;
                local_scalar_t__ c2(DUMMY_VAR__);
                (void) c2;  // dummy to suppress unused var warning
                stan::math::initialize(c2, DUMMY_VAR__);
                stan::math::fill(c2, DUMMY_VAR__);
                stan::math::assign(c2,(square(slab_scale) * get_base1(caux, 1, "caux", 1)));


                current_statement_begin__ = 304;
                if (as_bool((primitive_value(logical_eq(is_continuous, 1)) && primitive_value(logical_eq(family, 1))))) {
                    current_statement_begin__ = 305;
                    stan::math::assign(beta, hsplus_prior(z_beta, global, local, global_prior_scale, aux, c2, pstream__));
                } else {
                    current_statement_begin__ = 306;
                    stan::math::assign(beta, hsplus_prior(z_beta, global, local, global_prior_scale, 1, c2, pstream__));
                }
                }
            } else if (as_bool(logical_eq(prior_dist, 5))) {
                current_statement_begin__ = 309;
                stan::math::assign(beta, add(prior_mean, elt_multiply(elt_multiply(prior_scale, stan::math::sqrt(multiply(2, get_base1(mix, 1, "mix", 1)))), z_beta)));
            } else if (as_bool(logical_eq(prior_dist, 6))) {
                current_statement_begin__ = 311;
                stan::math::assign(beta, add(prior_mean, elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda, 1, "one_over_lambda", 1), prior_scale), stan::math::sqrt(multiply(2, get_base1(mix, 1, "mix", 1)))), z_beta)));
            } else if (as_bool(logical_eq(prior_dist, 7))) {
                {
                current_statement_begin__ = 313;
                int z_pos(0);
                (void) z_pos;  // dummy to suppress unused var warning
                stan::math::fill(z_pos, std::numeric_limits<int>::min());
                stan::math::assign(z_pos,1);


                current_statement_begin__ = 314;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 315;
                    stan::model::assign(beta, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                get_base1(z_beta, z_pos, "z_beta", 1), 
                                "assigning variable beta");
                    current_statement_begin__ = 316;
                    stan::math::assign(z_pos, (z_pos + 1));
                    current_statement_begin__ = 317;
                    for (int n = 2; n <= get_base1(num_normals, k, "num_normals", 1); ++n) {

                        current_statement_begin__ = 318;
                        stan::model::assign(beta, 
                                    stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                    (stan::model::rvalue(beta, stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), "beta") * get_base1(z_beta, z_pos, "z_beta", 1)), 
                                    "assigning variable beta");
                        current_statement_begin__ = 319;
                        stan::math::assign(z_pos, (z_pos + 1));
                    }
                    current_statement_begin__ = 321;
                    stan::model::assign(beta, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                (stan::model::rvalue(beta, stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), "beta") * pow(get_base1(prior_scale, k, "prior_scale", 1), get_base1(num_normals, k, "num_normals", 1))), 
                                "assigning variable beta");
                    current_statement_begin__ = 322;
                    stan::model::assign(beta, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                (stan::model::rvalue(beta, stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), "beta") + get_base1(prior_mean, k, "prior_mean", 1)), 
                                "assigning variable beta");
                }
                }
            }
            current_statement_begin__ = 327;
            if (as_bool(logical_eq(prior_dist_for_aux, 0))) {
                current_statement_begin__ = 328;
                stan::math::assign(aux, aux_unscaled);
            } else {

                current_statement_begin__ = 330;
                stan::math::assign(aux, (prior_scale_for_aux * aux_unscaled));
                current_statement_begin__ = 331;
                if (as_bool(logical_lte(prior_dist_for_aux, 2))) {
                    current_statement_begin__ = 332;
                    stan::math::assign(aux, (aux + prior_mean_for_aux));
                }
            }
            current_statement_begin__ = 335;
            stan::math::assign(theta_L, make_theta_L(len_theta_L, p, aux, tau, scale, zeta, rho, z_T, pstream__));
            current_statement_begin__ = 337;
            stan::math::assign(b, make_b(z_b, theta_L, p, l, pstream__));

            // validate transformed parameters
            const char* function__ = "validate transformed params";
            (void) function__;  // dummy to suppress unused var warning

            current_statement_begin__ = 283;
            if (stan::math::is_uninitialized(aux)) {
                std::stringstream msg__;
                msg__ << "Undefined transformed parameter: aux";
                stan::lang::rethrow_located(std::runtime_error(std::string("Error initializing variable aux: ") + msg__.str()), current_statement_begin__, prog_reader__());
            }
            current_statement_begin__ = 288;
            size_t beta_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < beta_j_1_max__; ++j_1__) {
                if (stan::math::is_uninitialized(beta(j_1__))) {
                    std::stringstream msg__;
                    msg__ << "Undefined transformed parameter: beta" << "(" << j_1__ << ")";
                    stan::lang::rethrow_located(std::runtime_error(std::string("Error initializing variable beta: ") + msg__.str()), current_statement_begin__, prog_reader__());
                }
            }
            current_statement_begin__ = 289;
            size_t b_j_1_max__ = q;
            for (size_t j_1__ = 0; j_1__ < b_j_1_max__; ++j_1__) {
                if (stan::math::is_uninitialized(b(j_1__))) {
                    std::stringstream msg__;
                    msg__ << "Undefined transformed parameter: b" << "(" << j_1__ << ")";
                    stan::lang::rethrow_located(std::runtime_error(std::string("Error initializing variable b: ") + msg__.str()), current_statement_begin__, prog_reader__());
                }
            }
            current_statement_begin__ = 290;
            size_t theta_L_j_1_max__ = len_theta_L;
            for (size_t j_1__ = 0; j_1__ < theta_L_j_1_max__; ++j_1__) {
                if (stan::math::is_uninitialized(theta_L(j_1__))) {
                    std::stringstream msg__;
                    msg__ << "Undefined transformed parameter: theta_L" << "(" << j_1__ << ")";
                    stan::lang::rethrow_located(std::runtime_error(std::string("Error initializing variable theta_L: ") + msg__.str()), current_statement_begin__, prog_reader__());
                }
            }

            // model body
            {
            current_statement_begin__ = 340;
            validate_non_negative_index("eta", "N", N);
            Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> eta(N);
            stan::math::initialize(eta, DUMMY_VAR__);
            stan::math::fill(eta, DUMMY_VAR__);

            current_statement_begin__ = 341;
            local_scalar_t__ dummy(DUMMY_VAR__);
            (void) dummy;  // dummy to suppress unused var warning
            stan::math::initialize(dummy, DUMMY_VAR__);
            stan::math::fill(dummy, DUMMY_VAR__);


            current_statement_begin__ = 343;
            stan::math::assign(eta, offset_);
            current_statement_begin__ = 344;
            if (as_bool(logical_gt(K, 0)))
              stan::math::assign(eta, add(eta, multiply(X, beta)));
            current_statement_begin__ = 345;
            stan::math::assign(eta, add(eta, csr_matrix_times_vector3(N, q, w, v, u, b, pstream__)));
            current_statement_begin__ = 347;
            if (as_bool(logical_eq(has_intercept, 1))) {

                current_statement_begin__ = 348;
                if (as_bool((primitive_value((primitive_value(logical_eq(family, 1)) || primitive_value(logical_eq(link, 2)))) || primitive_value((primitive_value(logical_eq(family, 4)) && primitive_value(logical_neq(link, 5))))))) {
                    current_statement_begin__ = 348;
                    stan::math::assign(eta, add(eta, get_base1(gamma, 1, "gamma", 1)));
                } else if (as_bool((primitive_value(logical_eq(family, 4)) && primitive_value(logical_eq(link, 5))))) {
                    current_statement_begin__ = 349;
                    stan::math::assign(eta, add(eta, (get_base1(gamma, 1, "gamma", 1) - max(eta))));
                } else {
                    current_statement_begin__ = 350;
                    stan::math::assign(eta, add(eta, (get_base1(gamma, 1, "gamma", 1) - min(eta))));
                }
            }
            current_statement_begin__ = 353;
            if (as_bool(logical_eq(has_weights, 0))) {

                current_statement_begin__ = 354;
                lp_accum__.add(normal_log(y, eta, aux));
            } else {
                {
                current_statement_begin__ = 356;
                validate_non_negative_index("summands", "N", N);
                Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> summands(N);
                stan::math::initialize(summands, DUMMY_VAR__);
                stan::math::fill(summands, DUMMY_VAR__);


                current_statement_begin__ = 357;
                stan::math::assign(summands, pw_gauss(y, eta, aux, pstream__));
                current_statement_begin__ = 358;
                lp_accum__.add(dot_product(weights, summands));
                }
            }
            current_statement_begin__ = 361;
            if (as_bool((primitive_value(logical_gt(prior_dist_for_aux, 0)) && primitive_value(logical_gt(prior_scale_for_aux, 0))))) {
                {
                current_statement_begin__ = 362;
                local_scalar_t__ log_half(DUMMY_VAR__);
                (void) log_half;  // dummy to suppress unused var warning
                stan::math::initialize(log_half, DUMMY_VAR__);
                stan::math::fill(log_half, DUMMY_VAR__);
                stan::math::assign(log_half,-(0.693147180559945286));


                current_statement_begin__ = 363;
                if (as_bool(logical_eq(prior_dist_for_aux, 1))) {
                    current_statement_begin__ = 364;
                    lp_accum__.add((normal_log(aux_unscaled, 0, 1) - log_half));
                } else if (as_bool(logical_eq(prior_dist_for_aux, 2))) {
                    current_statement_begin__ = 366;
                    lp_accum__.add((student_t_log(aux_unscaled, prior_df_for_aux, 0, 1) - log_half));
                } else {
                    current_statement_begin__ = 368;
                    lp_accum__.add(exponential_log(aux_unscaled, 1));
                }
                }
            }
            current_statement_begin__ = 373;
            if (as_bool(logical_eq(prior_dist, 1))) {
                current_statement_begin__ = 373;
                lp_accum__.add(normal_log(z_beta, 0, 1));
            } else if (as_bool(logical_eq(prior_dist, 2))) {
                current_statement_begin__ = 374;
                lp_accum__.add(normal_log(z_beta, 0, 1));
            } else if (as_bool(logical_eq(prior_dist, 3))) {
                {
                current_statement_begin__ = 376;
                local_scalar_t__ log_half(DUMMY_VAR__);
                (void) log_half;  // dummy to suppress unused var warning
                stan::math::initialize(log_half, DUMMY_VAR__);
                stan::math::fill(log_half, DUMMY_VAR__);
                stan::math::assign(log_half,-(0.693147180559945286));


                current_statement_begin__ = 377;
                lp_accum__.add(normal_log(z_beta, 0, 1));
                current_statement_begin__ = 378;
                lp_accum__.add((normal_log(get_base1(local, 1, "local", 1), 0, 1) - log_half));
                current_statement_begin__ = 379;
                lp_accum__.add(inv_gamma_log(get_base1(local, 2, "local", 1), multiply(0.5, prior_df), multiply(0.5, prior_df)));
                current_statement_begin__ = 380;
                lp_accum__.add((normal_log(get_base1(global, 1, "global", 1), 0, 1) - log_half));
                current_statement_begin__ = 381;
                lp_accum__.add(inv_gamma_log(get_base1(global, 2, "global", 1), (0.5 * global_prior_df), (0.5 * global_prior_df)));
                current_statement_begin__ = 382;
                lp_accum__.add(inv_gamma_log(caux, (0.5 * slab_df), (0.5 * slab_df)));
                }
            } else if (as_bool(logical_eq(prior_dist, 4))) {
                {
                current_statement_begin__ = 385;
                local_scalar_t__ log_half(DUMMY_VAR__);
                (void) log_half;  // dummy to suppress unused var warning
                stan::math::initialize(log_half, DUMMY_VAR__);
                stan::math::fill(log_half, DUMMY_VAR__);
                stan::math::assign(log_half,-(0.693147180559945286));


                current_statement_begin__ = 386;
                lp_accum__.add(normal_log(z_beta, 0, 1));
                current_statement_begin__ = 387;
                lp_accum__.add((normal_log(get_base1(local, 1, "local", 1), 0, 1) - log_half));
                current_statement_begin__ = 388;
                lp_accum__.add(inv_gamma_log(get_base1(local, 2, "local", 1), multiply(0.5, prior_df), multiply(0.5, prior_df)));
                current_statement_begin__ = 389;
                lp_accum__.add((normal_log(get_base1(local, 3, "local", 1), 0, 1) - log_half));
                current_statement_begin__ = 391;
                lp_accum__.add(inv_gamma_log(get_base1(local, 4, "local", 1), multiply(0.5, prior_scale), multiply(0.5, prior_scale)));
                current_statement_begin__ = 392;
                lp_accum__.add((normal_log(get_base1(global, 1, "global", 1), 0, 1) - log_half));
                current_statement_begin__ = 393;
                lp_accum__.add(inv_gamma_log(get_base1(global, 2, "global", 1), (0.5 * global_prior_df), (0.5 * global_prior_df)));
                current_statement_begin__ = 394;
                lp_accum__.add(inv_gamma_log(caux, (0.5 * slab_df), (0.5 * slab_df)));
                }
            } else if (as_bool(logical_eq(prior_dist, 5))) {

                current_statement_begin__ = 397;
                lp_accum__.add(normal_log(z_beta, 0, 1));
                current_statement_begin__ = 398;
                lp_accum__.add(exponential_log(get_base1(mix, 1, "mix", 1), 1));
            } else if (as_bool(logical_eq(prior_dist, 6))) {

                current_statement_begin__ = 401;
                lp_accum__.add(normal_log(z_beta, 0, 1));
                current_statement_begin__ = 402;
                lp_accum__.add(exponential_log(get_base1(mix, 1, "mix", 1), 1));
                current_statement_begin__ = 403;
                lp_accum__.add(chi_square_log(get_base1(one_over_lambda, 1, "one_over_lambda", 1), get_base1(prior_df, 1, "prior_df", 1)));
            } else if (as_bool(logical_eq(prior_dist, 7))) {

                current_statement_begin__ = 406;
                lp_accum__.add(normal_log(z_beta, 0, 1));
            }
            current_statement_begin__ = 411;
            if (as_bool(logical_eq(has_intercept, 1))) {

                current_statement_begin__ = 412;
                if (as_bool(logical_eq(prior_dist_for_intercept, 1))) {
                    current_statement_begin__ = 413;
                    lp_accum__.add(normal_log(gamma, prior_mean_for_intercept, prior_scale_for_intercept));
                } else if (as_bool(logical_eq(prior_dist_for_intercept, 2))) {
                    current_statement_begin__ = 415;
                    lp_accum__.add(student_t_log(gamma, prior_df_for_intercept, prior_mean_for_intercept, prior_scale_for_intercept));
                }
            }
            current_statement_begin__ = 420;
            stan::math::assign(dummy, decov_lp(z_b, z_T, rho, zeta, tau, regularization, delta, shape, t, p, lp__, lp_accum__, pstream__));
            }

        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }

        lp_accum__.add(lp__);
        return lp_accum__.sum();

    } // log_prob()

    template <bool propto, bool jacobian, typename T_>
    T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,
               std::ostream* pstream = 0) const {
      std::vector<T_> vec_params_r;
      vec_params_r.reserve(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        vec_params_r.push_back(params_r(i));
      std::vector<int> vec_params_i;
      return log_prob<propto,jacobian,T_>(vec_params_r, vec_params_i, pstream);
    }
    
    template <typename T__>
    T__ get_aux(const T__* sample) const {
      typedef T__ local_scalar_t__;
      
      size_t aux_offset = 
        has_intercept + // gammma
        (prior_dist == 7 ? sum(num_normals) : K) + // z_beta
        hs + // global
        hs * K + //local
        (hs > 0 ? 1 : 0) + // caux
        (prior_dist == 5 || prior_dist == 6 ? K : 0) + // mix
        (prior_dist == 6 ? 1 : 0) + // one_over_lambda
        q + // z_b
        len_z_T + // z_T
        len_rho + // rho
        len_concentration + // zeta
        t + // tau
        1; // aux_unscaled
        // 1 //  aux
        // K // beta
        // q // b
        // len_theta_L // theta_L

      return sample[aux_offset];
    }
    
    template <typename T__>
    void get_parametric_mean(const T__* sample,  T__* result) const {
      typedef T__ local_scalar_t__;
      
      size_t offset = 0;
      
      local_scalar_t__ gamma;
      if (has_intercept) gamma = sample[offset++];
      
      size_t z_beta_length = (prior_dist == 7 ? sum(num_normals) : K);
      /* Eigen::Map<const Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> >
        z_beta(sample + offset, z_beta_length); */
      offset += z_beta_length;
      
      /*std::vector<local_scalar_t__> global;
      std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > local;
      std::vector<local_scalar_t__> caux;
      if (hs > 0) { 
        global.push_back(sample[offset++]);
        
        local.reserve(K);
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>temp(K);
        for (size_t k = 0; k < static_cast<size_t>(K); ++k)
          temp(k) = sample[offset + k];
        local.push_back(temp);
        offset += K;
        
        caux.push_back(sample[offset++]);
      }*/
      if (hs > 0) offset += 2 + K;
      
      /*std::vector<Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > mix;
      size_t mix_length = (prior_dist == 5 || prior_dist == 6 ? 1 : 0);
      mix.reserve(mix_length);
      for (size_t i_mix = 0; i_mix < mix_length; ++i_mix) {
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>temp(K);
        for (int k = 0; k < K; ++k)
          temp(k) = sample[offset + k];
        mix.push_back(temp);
        offset += K;
      }*/
      if (prior_dist == 5 || prior_dist == 6) offset += K;
      
      /*std::vector<local_scalar_t__> one_over_lambda;
      if (prior_dist == 6)
        one_over_lambda.push_back(sample[offset++]);*/
      if (prior_dist == 6) offset += 1;
       
      // Eigen::Map<const Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > z_b(sample + offset, q);
      offset += q;
      
      // Eigen::Map<const Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > z_T(sample + offset, len_z_T);
      offset += len_z_T;
      
      // Eigen::Map<const Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > rho(sample + offset, len_rho);
      offset += len_rho;
      
      // Eigen::Map<const Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > zeta(sample + offset, len_concentration);
      offset += len_concentration;
      
      // Eigen::Map<const Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > tau(sample + offset, t);
      offset += t;
      
      //local_scalar_t__ aux_unscaled = sample[offset++];
      offset += 1;
      
      /* extract transformed parameters from sample */
      //local_scalar_t__ aux = sample[offset++];
      offset += 1;
      
      Eigen::Map<const Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > beta(sample + offset, K);
      offset += K; 
      Eigen::Map<const Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > b(sample + offset, q);
      // offset += q;
      // Eigen::Map<const Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > theta_L(sample + offset, len_theta_L);

      
      /* recreate transformed parameters from sample */
      /*
      local_scalar_t__ aux;
      if (prior_dist_for_aux == 0) {
        aux = aux_unscaled;
      } else {
        aux = prior_scale_for_aux * aux_unscaled;
        if (prior_dist_for_aux <= 2)
           aux += prior_mean_for_aux;
      }
      
      Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> beta(K);
      if (prior_dist == 0) {
        beta = z_beta;
      } else if (prior_dist == 1) {
        beta = z_beta * prior_scale + prior_mean;
      } else if (prior_dist == 2) {
        for (int k = 0; k < K; ++k) {
          beta(k) = CFt(z_beta(k), prior_df[k], NULL) * prior_scale[k] + prior_mean[k];
        }
      } else if (prior_dist == 3) {
        local_scalar_t__ c2 = slab_scale * slab_scale * caux[0];
        // because too many functions are not capable of handling Eigen maps
        // got lazy and make a local copy instead 
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z_beta_copy(K);
        z_beta_copy = z_beta;
        if (is_continuous == 1 && family == 1) {
          beta = hs_prior(z_beta_copy, global, local, global_prior_scale, aux, c2, NULL);
        } else {
          beta = hs_prior(z_beta_copy, global, local, global_prior_scale, 1, c2, NULL);
        }
      } else if (prior_dist == 4) {
        local_scalar_t__ c2 = slab_scale * slab_scale * caux[0];
        
        Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> z_beta_copy(K);
        z_beta_copy = z_beta;
        if (is_continuous == 1 && family == 1) {
          beta = hsplus_prior(z_beta_copy, global, local, global_prior_scale, aux, c2, NULL);
        } else {
          beta = hsplus_prior(z_beta_copy, global, local, global_prior_scale, 1, c2, NULL);
        }
      } else if (prior_dist == 5) {
        beta = (prior_scale * sqrt(2 * mix[0])) * z_beta + prior_mean;
      } else if (prior_dist == 6) {
        beta = one_over_lambda[0] * prior_scale * sqrt(2 * mix[0]) * z_beta + prior_mean;
      } else if (prior_dist == 7) {
        int z_pos = 0;
        for (int k = 0; k < K; ++k) {
          beta(k) = z_beta[z_pos++];
          for (int n = 1; n < num_normals[k]; ++n) {
            beta(k) *= z_beta[z_pos++];
          }
          beta(k) = beta(k) * std::pow(prior_scale[k], num_normals[k]) + prior_mean(k);
        }
      }
      
      Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> theta_L(len_theta_L);
      theta_L = make_theta_L(len_theta_L, p, aux, tau, scale, zeta, rho, z_T, NULL);
      
      Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> b(q);
      b = make_b(z_b, theta_L, p, l, NULL);
      */
      
      Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> eta(N);
      if (K > 0) {
        eta = X * beta;
      } else {
        eta = Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>::Zero(N);
      }
      eta += csr_matrix_times_vector3(N, q, w, v, u, b, NULL);
      
      if (has_intercept) {
        if ((family == 1 || link == 2) || (family == 4 && link != 5))
          eta += Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>::Constant(N, gamma);
        else if (family == 4 && link == 5)
          eta += Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>::Constant(N, gamma - max(eta));
        else
          eta += Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>::Constant(N, gamma - min(eta));
      }
      
      std::memcpy(result, const_cast<const local_scalar_t__*>(eta.data()), N * sizeof(local_scalar_t__));
    }
    
    template <typename T__>
    void get_parametric_mean(const T__* sample,  T__* result, bool include_fixed, bool include_random) const
    {
      typedef T__ local_scalar_t__;
      
      size_t offset = 0;
      
      local_scalar_t__ gamma;
      if (has_intercept) gamma = sample[offset++];
      
      size_t z_beta_length = (prior_dist == 7 ? sum(num_normals) : K);
      offset += z_beta_length;
      
      if (hs > 0) offset += 2 + K;
      
      if (prior_dist == 5 || prior_dist == 6) offset += K;
      
      if (prior_dist == 6) offset += 1;
       
      offset += q;
      
      offset += len_z_T;
      
      offset += len_rho;
      
      offset += len_concentration;
      
      offset += t;
      
      offset += 1;
      
      /* extract transformed parameters from sample */
      offset += 1;
      
      Eigen::Map<const Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > beta(sample + offset, K);
      offset += K; 
      Eigen::Map<const Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> > b(sample + offset, q);
      
      
      Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1> eta(N);
      eta = Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>::Zero(N);
      
      if (include_fixed) {
        if (K > 0)
          eta += X * beta;
                
        if (has_intercept) {
          if ((family == 1 || link == 2) || (family == 4 && link != 5))
            eta += Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>::Constant(N, gamma);
          else if (family == 4 && link == 5)
            eta += Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>::Constant(N, gamma - max(eta));
          else
            eta += Eigen::Matrix<local_scalar_t__, Eigen::Dynamic, 1>::Constant(N, gamma - min(eta));
        }
      }
      if (include_random) {
        eta += csr_matrix_times_vector3(N, q, w, v, u, b, NULL);
      }
      
      std::memcpy(result, const_cast<const local_scalar_t__*>(eta.data()), N * sizeof(local_scalar_t__));
    }

    void get_param_names(std::vector<std::string>& names__) const {
        names__.resize(0);
        names__.push_back("gamma");
        names__.push_back("z_beta");
        names__.push_back("global");
        names__.push_back("local");
        names__.push_back("caux");
        names__.push_back("mix");
        names__.push_back("one_over_lambda");
        names__.push_back("z_b");
        names__.push_back("z_T");
        names__.push_back("rho");
        names__.push_back("zeta");
        names__.push_back("tau");
        names__.push_back("aux_unscaled");
        names__.push_back("aux");
        names__.push_back("beta");
        names__.push_back("b");
        names__.push_back("theta_L");
    }


    void get_dims(std::vector<std::vector<size_t> >& dimss__) const {
        dimss__.resize(0);
        std::vector<size_t> dims__;
        dims__.resize(0);
        dims__.push_back(has_intercept);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((logical_eq(prior_dist, 7) ? sum(num_normals) : K ));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(hs);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(hs);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(logical_gt(hs, 0));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back((primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6))));
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(logical_eq(prior_dist, 6));
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_z_T);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_rho);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_concentration);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(t);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(K);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(q);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(len_theta_L);
        dimss__.push_back(dims__);
    }

    template <typename RNG>
    void write_array(RNG& base_rng__,
                     std::vector<double>& params_r__,
                     std::vector<int>& params_i__,
                     std::vector<double>& vars__,
                     bool include_tparams__ = true,
                     bool include_gqs__ = true,
                     std::ostream* pstream__ = 0) const {
        typedef double local_scalar_t__;

        vars__.resize(0);
        stan::io::reader<local_scalar_t__> in__(params_r__, params_i__);
        static const char* function__ = "model_continuous_namespace::write_array";
        (void) function__;  // dummy to suppress unused var warning

        // read-transform, write parameters
        std::vector<double> gamma;
        size_t gamma_d_0_max__ = has_intercept;
        gamma.reserve(gamma_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < gamma_d_0_max__; ++d_0__) {
            gamma.push_back(in__.scalar_lub_constrain(stan::math::negative_infinity(), stan::math::positive_infinity()));
        }
        size_t gamma_k_0_max__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < gamma_k_0_max__; ++k_0__) {
            vars__.push_back(gamma[k_0__]);
        }

        Eigen::Matrix<double, Eigen::Dynamic, 1> z_beta = in__.vector_constrain((logical_eq(prior_dist, 7) ? sum(num_normals) : K ));
        size_t z_beta_j_1_max__ = (logical_eq(prior_dist, 7) ? sum(num_normals) : K );
        for (size_t j_1__ = 0; j_1__ < z_beta_j_1_max__; ++j_1__) {
            vars__.push_back(z_beta(j_1__));
        }

        std::vector<double> global;
        size_t global_d_0_max__ = hs;
        global.reserve(global_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < global_d_0_max__; ++d_0__) {
            global.push_back(in__.scalar_lb_constrain(0));
        }
        size_t global_k_0_max__ = hs;
        for (size_t k_0__ = 0; k_0__ < global_k_0_max__; ++k_0__) {
            vars__.push_back(global[k_0__]);
        }

        std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > local;
        size_t local_d_0_max__ = hs;
        local.reserve(local_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < local_d_0_max__; ++d_0__) {
            local.push_back(in__.vector_lb_constrain(0, K));
        }
        size_t local_j_1_max__ = K;
        size_t local_k_0_max__ = hs;
        for (size_t j_1__ = 0; j_1__ < local_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < local_k_0_max__; ++k_0__) {
                vars__.push_back(local[k_0__](j_1__));
            }
        }

        std::vector<double> caux;
        size_t caux_d_0_max__ = logical_gt(hs, 0);
        caux.reserve(caux_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < caux_d_0_max__; ++d_0__) {
            caux.push_back(in__.scalar_lb_constrain(0));
        }
        size_t caux_k_0_max__ = logical_gt(hs, 0);
        for (size_t k_0__ = 0; k_0__ < caux_k_0_max__; ++k_0__) {
            vars__.push_back(caux[k_0__]);
        }

        std::vector<Eigen::Matrix<double, Eigen::Dynamic, 1> > mix;
        size_t mix_d_0_max__ = (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)));
        mix.reserve(mix_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < mix_d_0_max__; ++d_0__) {
            mix.push_back(in__.vector_lb_constrain(0, K));
        }
        size_t mix_j_1_max__ = K;
        size_t mix_k_0_max__ = (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)));
        for (size_t j_1__ = 0; j_1__ < mix_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mix_k_0_max__; ++k_0__) {
                vars__.push_back(mix[k_0__](j_1__));
            }
        }

        std::vector<double> one_over_lambda;
        size_t one_over_lambda_d_0_max__ = logical_eq(prior_dist, 6);
        one_over_lambda.reserve(one_over_lambda_d_0_max__);
        for (size_t d_0__ = 0; d_0__ < one_over_lambda_d_0_max__; ++d_0__) {
            one_over_lambda.push_back(in__.scalar_lb_constrain(0));
        }
        size_t one_over_lambda_k_0_max__ = logical_eq(prior_dist, 6);
        for (size_t k_0__ = 0; k_0__ < one_over_lambda_k_0_max__; ++k_0__) {
            vars__.push_back(one_over_lambda[k_0__]);
        }

        Eigen::Matrix<double, Eigen::Dynamic, 1> z_b = in__.vector_constrain(q);
        size_t z_b_j_1_max__ = q;
        for (size_t j_1__ = 0; j_1__ < z_b_j_1_max__; ++j_1__) {
            vars__.push_back(z_b(j_1__));
        }

        Eigen::Matrix<double, Eigen::Dynamic, 1> z_T = in__.vector_constrain(len_z_T);
        size_t z_T_j_1_max__ = len_z_T;
        for (size_t j_1__ = 0; j_1__ < z_T_j_1_max__; ++j_1__) {
            vars__.push_back(z_T(j_1__));
        }

        Eigen::Matrix<double, Eigen::Dynamic, 1> rho = in__.vector_lub_constrain(0, 1, len_rho);
        size_t rho_j_1_max__ = len_rho;
        for (size_t j_1__ = 0; j_1__ < rho_j_1_max__; ++j_1__) {
            vars__.push_back(rho(j_1__));
        }

        Eigen::Matrix<double, Eigen::Dynamic, 1> zeta = in__.vector_lb_constrain(0, len_concentration);
        size_t zeta_j_1_max__ = len_concentration;
        for (size_t j_1__ = 0; j_1__ < zeta_j_1_max__; ++j_1__) {
            vars__.push_back(zeta(j_1__));
        }

        Eigen::Matrix<double, Eigen::Dynamic, 1> tau = in__.vector_lb_constrain(0, t);
        size_t tau_j_1_max__ = t;
        for (size_t j_1__ = 0; j_1__ < tau_j_1_max__; ++j_1__) {
            vars__.push_back(tau(j_1__));
        }

        double aux_unscaled = in__.scalar_lb_constrain(0);
        vars__.push_back(aux_unscaled);

        double lp__ = 0.0;
        (void) lp__;  // dummy to suppress unused var warning
        stan::math::accumulator<double> lp_accum__;

        local_scalar_t__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        if (!include_tparams__ && !include_gqs__) return;

        try {
            // declare and define transformed parameters
            current_statement_begin__ = 283;
            double aux;
            (void) aux;  // dummy to suppress unused var warning
            stan::math::initialize(aux, DUMMY_VAR__);
            stan::math::fill(aux, DUMMY_VAR__);
            stan::math::assign(aux,(logical_eq(prior_dist_for_aux, 0) ? stan::math::promote_scalar<local_scalar_t__>(aux_unscaled) : stan::math::promote_scalar<local_scalar_t__>((logical_lte(prior_dist_for_aux, 2) ? stan::math::promote_scalar<local_scalar_t__>(((prior_scale_for_aux * aux_unscaled) + prior_mean_for_aux)) : stan::math::promote_scalar<local_scalar_t__>((prior_scale_for_aux * aux_unscaled)) )) ));

            current_statement_begin__ = 288;
            validate_non_negative_index("beta", "K", K);
            Eigen::Matrix<double, Eigen::Dynamic, 1> beta(K);
            stan::math::initialize(beta, DUMMY_VAR__);
            stan::math::fill(beta, DUMMY_VAR__);

            current_statement_begin__ = 289;
            validate_non_negative_index("b", "q", q);
            Eigen::Matrix<double, Eigen::Dynamic, 1> b(q);
            stan::math::initialize(b, DUMMY_VAR__);
            stan::math::fill(b, DUMMY_VAR__);

            current_statement_begin__ = 290;
            validate_non_negative_index("theta_L", "len_theta_L", len_theta_L);
            Eigen::Matrix<double, Eigen::Dynamic, 1> theta_L(len_theta_L);
            stan::math::initialize(theta_L, DUMMY_VAR__);
            stan::math::fill(theta_L, DUMMY_VAR__);

            // do transformed parameters statements
            current_statement_begin__ = 291;
            if (as_bool(logical_eq(prior_dist, 0))) {
                current_statement_begin__ = 291;
                stan::math::assign(beta, z_beta);
            } else if (as_bool(logical_eq(prior_dist, 1))) {
                current_statement_begin__ = 292;
                stan::math::assign(beta, add(elt_multiply(z_beta, prior_scale), prior_mean));
            } else if (as_bool(logical_eq(prior_dist, 2))) {
                current_statement_begin__ = 293;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 294;
                    stan::model::assign(beta, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                ((CFt(get_base1(z_beta, k, "z_beta", 1), get_base1(prior_df, k, "prior_df", 1), pstream__) * get_base1(prior_scale, k, "prior_scale", 1)) + get_base1(prior_mean, k, "prior_mean", 1)), 
                                "assigning variable beta");
                }
            } else if (as_bool(logical_eq(prior_dist, 3))) {
                {
                current_statement_begin__ = 297;
                local_scalar_t__ c2(DUMMY_VAR__);
                (void) c2;  // dummy to suppress unused var warning
                stan::math::initialize(c2, DUMMY_VAR__);
                stan::math::fill(c2, DUMMY_VAR__);
                stan::math::assign(c2,(square(slab_scale) * get_base1(caux, 1, "caux", 1)));


                current_statement_begin__ = 298;
                if (as_bool((primitive_value(logical_eq(is_continuous, 1)) && primitive_value(logical_eq(family, 1))))) {
                    current_statement_begin__ = 299;
                    stan::math::assign(beta, hs_prior(z_beta, global, local, global_prior_scale, aux, c2, pstream__));
                } else {
                    current_statement_begin__ = 300;
                    stan::math::assign(beta, hs_prior(z_beta, global, local, global_prior_scale, 1, c2, pstream__));
                }
                }
            } else if (as_bool(logical_eq(prior_dist, 4))) {
                {
                current_statement_begin__ = 303;
                local_scalar_t__ c2(DUMMY_VAR__);
                (void) c2;  // dummy to suppress unused var warning
                stan::math::initialize(c2, DUMMY_VAR__);
                stan::math::fill(c2, DUMMY_VAR__);
                stan::math::assign(c2,(square(slab_scale) * get_base1(caux, 1, "caux", 1)));


                current_statement_begin__ = 304;
                if (as_bool((primitive_value(logical_eq(is_continuous, 1)) && primitive_value(logical_eq(family, 1))))) {
                    current_statement_begin__ = 305;
                    stan::math::assign(beta, hsplus_prior(z_beta, global, local, global_prior_scale, aux, c2, pstream__));
                } else {
                    current_statement_begin__ = 306;
                    stan::math::assign(beta, hsplus_prior(z_beta, global, local, global_prior_scale, 1, c2, pstream__));
                }
                }
            } else if (as_bool(logical_eq(prior_dist, 5))) {
                current_statement_begin__ = 309;
                stan::math::assign(beta, add(prior_mean, elt_multiply(elt_multiply(prior_scale, stan::math::sqrt(multiply(2, get_base1(mix, 1, "mix", 1)))), z_beta)));
            } else if (as_bool(logical_eq(prior_dist, 6))) {
                current_statement_begin__ = 311;
                stan::math::assign(beta, add(prior_mean, elt_multiply(elt_multiply(multiply(get_base1(one_over_lambda, 1, "one_over_lambda", 1), prior_scale), stan::math::sqrt(multiply(2, get_base1(mix, 1, "mix", 1)))), z_beta)));
            } else if (as_bool(logical_eq(prior_dist, 7))) {
                {
                current_statement_begin__ = 313;
                int z_pos(0);
                (void) z_pos;  // dummy to suppress unused var warning
                stan::math::fill(z_pos, std::numeric_limits<int>::min());
                stan::math::assign(z_pos,1);


                current_statement_begin__ = 314;
                for (int k = 1; k <= K; ++k) {

                    current_statement_begin__ = 315;
                    stan::model::assign(beta, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                get_base1(z_beta, z_pos, "z_beta", 1), 
                                "assigning variable beta");
                    current_statement_begin__ = 316;
                    stan::math::assign(z_pos, (z_pos + 1));
                    current_statement_begin__ = 317;
                    for (int n = 2; n <= get_base1(num_normals, k, "num_normals", 1); ++n) {

                        current_statement_begin__ = 318;
                        stan::model::assign(beta, 
                                    stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                    (stan::model::rvalue(beta, stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), "beta") * get_base1(z_beta, z_pos, "z_beta", 1)), 
                                    "assigning variable beta");
                        current_statement_begin__ = 319;
                        stan::math::assign(z_pos, (z_pos + 1));
                    }
                    current_statement_begin__ = 321;
                    stan::model::assign(beta, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                (stan::model::rvalue(beta, stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), "beta") * pow(get_base1(prior_scale, k, "prior_scale", 1), get_base1(num_normals, k, "num_normals", 1))), 
                                "assigning variable beta");
                    current_statement_begin__ = 322;
                    stan::model::assign(beta, 
                                stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), 
                                (stan::model::rvalue(beta, stan::model::cons_list(stan::model::index_uni(k), stan::model::nil_index_list()), "beta") + get_base1(prior_mean, k, "prior_mean", 1)), 
                                "assigning variable beta");
                }
                }
            }
            current_statement_begin__ = 327;
            if (as_bool(logical_eq(prior_dist_for_aux, 0))) {
                current_statement_begin__ = 328;
                stan::math::assign(aux, aux_unscaled);
            } else {

                current_statement_begin__ = 330;
                stan::math::assign(aux, (prior_scale_for_aux * aux_unscaled));
                current_statement_begin__ = 331;
                if (as_bool(logical_lte(prior_dist_for_aux, 2))) {
                    current_statement_begin__ = 332;
                    stan::math::assign(aux, (aux + prior_mean_for_aux));
                }
            }
            current_statement_begin__ = 335;
            stan::math::assign(theta_L, make_theta_L(len_theta_L, p, aux, tau, scale, zeta, rho, z_T, pstream__));
            current_statement_begin__ = 337;
            stan::math::assign(b, make_b(z_b, theta_L, p, l, pstream__));

            if (!include_gqs__ && !include_tparams__) return;
            // validate transformed parameters
            const char* function__ = "validate transformed params";
            (void) function__;  // dummy to suppress unused var warning

            // write transformed parameters
            if (include_tparams__) {
                vars__.push_back(aux);
                size_t beta_j_1_max__ = K;
                for (size_t j_1__ = 0; j_1__ < beta_j_1_max__; ++j_1__) {
                    vars__.push_back(beta(j_1__));
                }
                size_t b_j_1_max__ = q;
                for (size_t j_1__ = 0; j_1__ < b_j_1_max__; ++j_1__) {
                    vars__.push_back(b(j_1__));
                }
                size_t theta_L_j_1_max__ = len_theta_L;
                for (size_t j_1__ = 0; j_1__ < theta_L_j_1_max__; ++j_1__) {
                    vars__.push_back(theta_L(j_1__));
                }
            }
            if (!include_gqs__) return;
        } catch (const std::exception& e) {
            stan::lang::rethrow_located(e, current_statement_begin__, prog_reader__());
            // Next line prevents compiler griping about no return
            throw std::runtime_error("*** IF YOU SEE THIS, PLEASE REPORT A BUG ***");
        }
    }

    template <typename RNG>
    void write_array(RNG& base_rng,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& vars,
                     bool include_tparams = true,
                     bool include_gqs = true,
                     std::ostream* pstream = 0) const {
      std::vector<double> params_r_vec(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r_vec[i] = params_r(i);
      std::vector<double> vars_vec;
      std::vector<int> params_i_vec;
      write_array(base_rng, params_r_vec, params_i_vec, vars_vec, include_tparams, include_gqs, pstream);
      vars.resize(vars_vec.size());
      for (int i = 0; i < vars.size(); ++i)
        vars(i) = vars_vec[i];
    }

    std::string model_name() const {
        return "model_continuous";
    }


    void constrained_param_names(std::vector<std::string>& param_names__,
                                 bool include_tparams__ = true,
                                 bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        size_t gamma_k_0_max__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < gamma_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t z_beta_j_1_max__ = (logical_eq(prior_dist, 7) ? sum(num_normals) : K );
        for (size_t j_1__ = 0; j_1__ < z_beta_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t global_k_0_max__ = hs;
        for (size_t k_0__ = 0; k_0__ < global_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "global" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t local_j_1_max__ = K;
        size_t local_k_0_max__ = hs;
        for (size_t j_1__ = 0; j_1__ < local_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < local_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "local" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t caux_k_0_max__ = logical_gt(hs, 0);
        for (size_t k_0__ = 0; k_0__ < caux_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "caux" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t mix_j_1_max__ = K;
        size_t mix_k_0_max__ = (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)));
        for (size_t j_1__ = 0; j_1__ < mix_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mix_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t one_over_lambda_k_0_max__ = logical_eq(prior_dist, 6);
        for (size_t k_0__ = 0; k_0__ < one_over_lambda_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t z_b_j_1_max__ = q;
        for (size_t j_1__ = 0; j_1__ < z_b_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_b" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t z_T_j_1_max__ = len_z_T;
        for (size_t j_1__ = 0; j_1__ < z_T_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_T" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t rho_j_1_max__ = len_rho;
        for (size_t j_1__ = 0; j_1__ < rho_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "rho" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t zeta_j_1_max__ = len_concentration;
        for (size_t j_1__ = 0; j_1__ < zeta_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "zeta" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t tau_j_1_max__ = t;
        for (size_t j_1__ = 0; j_1__ < tau_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "tau" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "aux_unscaled";
        param_names__.push_back(param_name_stream__.str());

        if (!include_gqs__ && !include_tparams__) return;

        if (include_tparams__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "aux";
            param_names__.push_back(param_name_stream__.str());
            size_t beta_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < beta_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "beta" << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
            size_t b_j_1_max__ = q;
            for (size_t j_1__ = 0; j_1__ < b_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "b" << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
            size_t theta_L_j_1_max__ = len_theta_L;
            for (size_t j_1__ = 0; j_1__ < theta_L_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "theta_L" << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }

        if (!include_gqs__) return;
    }


    void unconstrained_param_names(std::vector<std::string>& param_names__,
                                   bool include_tparams__ = true,
                                   bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        size_t gamma_k_0_max__ = has_intercept;
        for (size_t k_0__ = 0; k_0__ < gamma_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "gamma" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t z_beta_j_1_max__ = (logical_eq(prior_dist, 7) ? sum(num_normals) : K );
        for (size_t j_1__ = 0; j_1__ < z_beta_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_beta" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t global_k_0_max__ = hs;
        for (size_t k_0__ = 0; k_0__ < global_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "global" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t local_j_1_max__ = K;
        size_t local_k_0_max__ = hs;
        for (size_t j_1__ = 0; j_1__ < local_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < local_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "local" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t caux_k_0_max__ = logical_gt(hs, 0);
        for (size_t k_0__ = 0; k_0__ < caux_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "caux" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t mix_j_1_max__ = K;
        size_t mix_k_0_max__ = (primitive_value(logical_eq(prior_dist, 5)) || primitive_value(logical_eq(prior_dist, 6)));
        for (size_t j_1__ = 0; j_1__ < mix_j_1_max__; ++j_1__) {
            for (size_t k_0__ = 0; k_0__ < mix_k_0_max__; ++k_0__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "mix" << '.' << k_0__ + 1 << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }
        size_t one_over_lambda_k_0_max__ = logical_eq(prior_dist, 6);
        for (size_t k_0__ = 0; k_0__ < one_over_lambda_k_0_max__; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "one_over_lambda" << '.' << k_0__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t z_b_j_1_max__ = q;
        for (size_t j_1__ = 0; j_1__ < z_b_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_b" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t z_T_j_1_max__ = len_z_T;
        for (size_t j_1__ = 0; j_1__ < z_T_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "z_T" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t rho_j_1_max__ = len_rho;
        for (size_t j_1__ = 0; j_1__ < rho_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "rho" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t zeta_j_1_max__ = len_concentration;
        for (size_t j_1__ = 0; j_1__ < zeta_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "zeta" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        size_t tau_j_1_max__ = t;
        for (size_t j_1__ = 0; j_1__ < tau_j_1_max__; ++j_1__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "tau" << '.' << j_1__ + 1;
            param_names__.push_back(param_name_stream__.str());
        }
        param_name_stream__.str(std::string());
        param_name_stream__ << "aux_unscaled";
        param_names__.push_back(param_name_stream__.str());

        if (!include_gqs__ && !include_tparams__) return;

        if (include_tparams__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "aux";
            param_names__.push_back(param_name_stream__.str());
            size_t beta_j_1_max__ = K;
            for (size_t j_1__ = 0; j_1__ < beta_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "beta" << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
            size_t b_j_1_max__ = q;
            for (size_t j_1__ = 0; j_1__ < b_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "b" << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
            size_t theta_L_j_1_max__ = len_theta_L;
            for (size_t j_1__ = 0; j_1__ < theta_L_j_1_max__; ++j_1__) {
                param_name_stream__.str(std::string());
                param_name_stream__ << "theta_L" << '.' << j_1__ + 1;
                param_names__.push_back(param_name_stream__.str());
            }
        }

        if (!include_gqs__) return;
    }

}; // model

}  // namespace

typedef model_continuous_namespace::model_continuous stan_model;

#ifndef USING_R

stan::model::model_base& new_model(
        stan::io::var_context& data_context,
        unsigned int seed,
        std::ostream* msg_stream) {
  stan_model* m = new stan_model(data_context, seed, msg_stream);
  return *m;
}

#endif


#endif
